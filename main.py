#!/usr/bin/env python3
"""
å¤§æ¨¡å‹æ•°æ®é›†ä¸‹è½½ç®¡ç†å·¥å…·
åŸºäºaria2cå’Œwgetçš„ç®€å•ä¸‹è½½ç®¡ç†å™¨
"""

import argparse
import sys
import os
from pathlib import Path
import time

from dataset_manager import DatasetManager
from downloader import DownloadManager
from task_manager import TaskManager
from utils import setup_logging, Colors, format_file_size
from system_monitor import SystemMonitor
from file_tracker import FileTracker
from config import get_config
from batch_downloader import BatchDownloadManager

def setup_delete_parser(subparsers):
    """è®¾ç½®åˆ é™¤ä»»åŠ¡è§£æå™¨"""
    parser = subparsers.add_parser('delete-task', help='åˆ é™¤ä»»åŠ¡')
    parser.add_argument('task_id', help='ä»»åŠ¡ID')
    parser.add_argument('--force', action='store_true', help='å¼ºåˆ¶åˆ é™¤ï¼Œä¸è¯¢é—®ç¡®è®¤')
    parser.add_argument('--keep-files', action='store_true', help='ä¿ç•™ä¸‹è½½çš„æ–‡ä»¶ï¼Œåªåˆ é™¤ä»»åŠ¡è®°å½•')

def setup_cleanup_parser(subparsers):
    """è®¾ç½®æ¸…ç†æ‰€æœ‰ä»»åŠ¡è§£æå™¨"""
    parser = subparsers.add_parser('cleanup', help='æ¸…ç†æ‰€æœ‰ä»»åŠ¡')
    parser.add_argument('--status', choices=['completed', 'failed', 'running', 'cancelled'], 
                       help='åªæ¸…ç†æŒ‡å®šçŠ¶æ€çš„ä»»åŠ¡')
    parser.add_argument('--force', action='store_true', help='å¼ºåˆ¶æ¸…ç†ï¼Œä¸è¯¢é—®ç¡®è®¤')
    parser.add_argument('--keep-files', action='store_true', help='ä¿ç•™ä¸‹è½½çš„æ–‡ä»¶ï¼Œåªåˆ é™¤ä»»åŠ¡è®°å½•')

def handle_delete_task(args):
    """å¤„ç†åˆ é™¤ä»»åŠ¡"""
    from utils import Colors
    
    task_manager = TaskManager()
    task = task_manager.get_task(args.task_id)
    
    if not task:
        print(f"{Colors.RED}ä»»åŠ¡ {args.task_id} ä¸å­˜åœ¨{Colors.NC}")
        return
    
    # æ˜¾ç¤ºä»»åŠ¡ä¿¡æ¯
    print(f"{Colors.BLUE}å‡†å¤‡åˆ é™¤ä»»åŠ¡:{Colors.NC}")
    print(f"  ID: {args.task_id}")
    print(f"  æ•°æ®é›†: {task['repo_id']}")
    print(f"  çŠ¶æ€: {task['status']}")
    print(f"  åˆ›å»ºæ—¶é—´: {task.get('created_at', 'Unknown')}")
    
    # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦æ­£åœ¨è¿è¡Œ
    if task['status'] == 'running' and not args.force:
        print(f"{Colors.YELLOW}è­¦å‘Šï¼šä»»åŠ¡æ­£åœ¨è¿è¡Œä¸­ï¼{Colors.NC}")
        response = input("æ˜¯å¦è¦å¼ºåˆ¶åˆ é™¤æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡ï¼Ÿ(y/N): ")
        if response.lower() != 'y':
            print("å–æ¶ˆåˆ é™¤")
            return
    
    # ç¡®è®¤åˆ é™¤
    if not args.force:
        action = "åˆ é™¤ä»»åŠ¡è®°å½•" if args.keep_files else "åˆ é™¤ä»»åŠ¡å’Œç›¸å…³æ–‡ä»¶"
        response = input(f"ç¡®è®¤{action}ï¼Ÿ(y/N): ")
        if response.lower() != 'y':
            print("å–æ¶ˆåˆ é™¤")
            return
    
    # æ‰§è¡Œåˆ é™¤
    success = delete_task_data(args.task_id, keep_files=args.keep_files)
    
    if success:
        print(f"{Colors.GREEN}âœ“ ä»»åŠ¡ {args.task_id} åˆ é™¤æˆåŠŸ{Colors.NC}")
    else:
        print(f"{Colors.RED}âœ— ä»»åŠ¡åˆ é™¤å¤±è´¥{Colors.NC}")

def handle_cleanup(args):
    """å¤„ç†æ¸…ç†æ‰€æœ‰ä»»åŠ¡"""
    from utils import Colors
    
    task_manager = TaskManager()
    all_tasks = task_manager.get_all_tasks()
    
    if not all_tasks:
        print(f"{Colors.YELLOW}æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ä»»åŠ¡{Colors.NC}")
        return
    
    # è¿‡æ»¤ä»»åŠ¡
    tasks_to_delete = []
    if args.status:
        tasks_to_delete = [task for task in all_tasks if task['status'] == args.status]
    else:
        tasks_to_delete = all_tasks
    
    if not tasks_to_delete:
        print(f"{Colors.YELLOW}æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ä»»åŠ¡{Colors.NC}")
        return
    
    print(f"{Colors.BLUE}å‡†å¤‡æ¸…ç† {len(tasks_to_delete)} ä¸ªä»»åŠ¡:{Colors.NC}")
    for task in tasks_to_delete:
        task_id = task.get('id') or task.get('task_id')  # å…¼å®¹ä¸åŒçš„IDå­—æ®µå
        repo_id = task.get('repo_id', 'Unknown')
        status = task.get('status', 'Unknown')
        print(f"  {task_id} - {repo_id} ({status})")
    
    # ç¡®è®¤æ¸…ç†
    if not args.force:
        action = "åˆ é™¤ä»»åŠ¡è®°å½•" if args.keep_files else "åˆ é™¤ä»»åŠ¡å’Œç›¸å…³æ–‡ä»¶"
        response = input(f"ç¡®è®¤{action}ï¼Ÿ(y/N): ")
        if response.lower() != 'y':
            print("å–æ¶ˆæ¸…ç†")
            return
    
    # æ‰§è¡Œæ¸…ç†
    success_count = 0
    for task in tasks_to_delete:
        task_id = task.get('id') or task.get('task_id')  # å…¼å®¹ä¸åŒçš„IDå­—æ®µå
        if delete_task_data(task_id, keep_files=args.keep_files):
            success_count += 1
            print(f"{Colors.GREEN}âœ“ åˆ é™¤ {task_id}{Colors.NC}")
        else:
            print(f"{Colors.RED}âœ— åˆ é™¤ {task_id} å¤±è´¥{Colors.NC}")
    
    print(f"{Colors.GREEN}æ¸…ç†å®Œæˆ: {success_count}/{len(tasks_to_delete)} ä¸ªä»»åŠ¡åˆ é™¤æˆåŠŸ{Colors.NC}")

def delete_task_data(task_id, keep_files=False):
    """åˆ é™¤ä»»åŠ¡æ•°æ®"""
    import shutil
    from pathlib import Path
    from utils import Colors
    
    try:
        config = get_config()
        task_manager = TaskManager()
        
        # è·å–ä»»åŠ¡ä¿¡æ¯
        task = task_manager.get_task(task_id)
        if not task:
            return False
        
        # åˆ é™¤ä»»åŠ¡è®°å½•
        if task_manager.delete_task(task_id):
            print(f"{Colors.GREEN}âœ“ ä»»åŠ¡è®°å½•åˆ é™¤æˆåŠŸ{Colors.NC}")
        else:
            print(f"{Colors.YELLOW}âš ï¸ ä»»åŠ¡è®°å½•åˆ é™¤å¤±è´¥{Colors.NC}")
        
        # åˆ é™¤å…ƒæ•°æ®ç›®å½•
        metadata_dir = config.get_metadata_dir() / 'tasks' / task_id
        if metadata_dir.exists():
            shutil.rmtree(metadata_dir)
            print(f"{Colors.GREEN}âœ“ å…ƒæ•°æ®åˆ é™¤æˆåŠŸ{Colors.NC}")
        
        # åˆ é™¤ä¸‹è½½æ–‡ä»¶ï¼ˆå¦‚æœä¸ä¿ç•™ï¼‰
        if not keep_files:
            repo_id = task['repo_id']
            download_path = None
            
            # å°è¯•ä»ä»»åŠ¡ä¸­è·å–è‡ªå®šä¹‰è·¯å¾„
            if task.get('local_dir'):
                download_path = Path(task['local_dir'])
            else:
                # ä½¿ç”¨é»˜è®¤ä¸‹è½½è·¯å¾„
                download_path = config.get_downloads_dir() / repo_id
            
            if download_path and download_path.exists():
                response = input(f"ç¡®è®¤åˆ é™¤ä¸‹è½½æ–‡ä»¶å¤¹ {download_path}ï¼Ÿ(y/N): ")
                if response.lower() == 'y':
                    shutil.rmtree(download_path)
                    print(f"{Colors.GREEN}âœ“ ä¸‹è½½æ–‡ä»¶åˆ é™¤æˆåŠŸ{Colors.NC}")
                else:
                    print(f"{Colors.YELLOW}ä¿ç•™ä¸‹è½½æ–‡ä»¶: {download_path}{Colors.NC}")
        
        return True
        
    except Exception as e:
        print(f"{Colors.RED}åˆ é™¤ä»»åŠ¡æ•°æ®å¤±è´¥: {str(e)}{Colors.NC}")
        return False

def main():
    parser = argparse.ArgumentParser(
        description='å¤§æ¨¡å‹æ•°æ®é›†ä¸‹è½½ç®¡ç†å·¥å…· - æ”¯æŒåˆ†æ‰¹ä¸‹è½½',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # åŸºæœ¬ä¸‹è½½
  python main.py download gpt2 --tool aria2c -x 8
  
  # æŒ‡å®šè‡ªå®šä¹‰è·¯å¾„
  python main.py --metadata-dir /path/to/metadata --downloads-dir /path/to/downloads download gpt2
  
  # åˆ†æ‰¹ä¸‹è½½å¤§æ•°æ®é›† (30TBæ•°æ®é›†, 10TBå¯ç”¨ç©ºé—´)
  python main.py analyze-dataset large-model/30tb-dataset --dataset
  python main.py plan-batch large-model/30tb-dataset --available-space 10737418240000 --dataset
  python main.py batch-download large-model/30tb-dataset --available-space 10737418240000 --dataset
  
  # æ¢ç›˜åç»§ç»­ä¸‹è½½
  python main.py batch-continue task_abc123 2
  
  # å¯¼å…¥HFDä»»åŠ¡
  python main.py import-hfd /path/to/dataset-dir /path/to/output
  python main.py import-hfd /path/to/dataset-dir/.hfd /path/to/output --dry-run
  
  # æŸ¥çœ‹ä»»åŠ¡çŠ¶æ€
  python main.py list-tasks
  python main.py batch-status task_abc123
        """
    )
    
    # å…¨å±€é…ç½®é€‰é¡¹
    parser.add_argument('--metadata-dir', help='å…ƒæ•°æ®å­˜å‚¨ç›®å½•ï¼ˆé»˜è®¤: metadataï¼‰')
    parser.add_argument('--downloads-dir', help='ä¸‹è½½æ–‡ä»¶å­˜å‚¨ç›®å½•ï¼ˆé»˜è®¤: downloadsï¼‰')
    parser.add_argument('--logs-dir', help='æ—¥å¿—æ–‡ä»¶å­˜å‚¨ç›®å½•ï¼ˆé»˜è®¤: logsï¼‰')
    
    # HFè®¤è¯å‚æ•°
    parser.add_argument('--hf-username', type=str, help='Hugging Face ç”¨æˆ·å (ç”¨äºéœ€è¦è®¤è¯çš„ä»“åº“)')
    parser.add_argument('--hf-token', type=str, help='Hugging Face è®¿é—®ä»¤ç‰Œ (ç”¨äºéœ€è¦è®¤è¯çš„ä»“åº“)')

    # ä»»åŠ¡ç®¡ç†å‚æ•°
    parser.add_argument('--create-task', action='store_true', help='åˆ›å»ºæ–°çš„ä¸‹è½½ä»»åŠ¡')
    parser.add_argument('--list-tasks', action='store_true', help='åˆ—å‡ºæ‰€æœ‰ä»»åŠ¡')
    parser.add_argument('--resume', action='store_true', help='æ¢å¤ä¸‹è½½ä»»åŠ¡')
    parser.add_argument('--status', action='store_true', help='æ˜¾ç¤ºä¸‹è½½çŠ¶æ€')
    parser.add_argument('--task-id', type=str, help='æŒ‡å®šä»»åŠ¡ID')
    parser.add_argument('--cancel', action='store_true', help='å–æ¶ˆä»»åŠ¡')
    parser.add_argument('--delete-task', action='store_true', help='åˆ é™¤ä»»åŠ¡')
    parser.add_argument('--task-detail', action='store_true', help='æ˜¾ç¤ºä»»åŠ¡è¯¦æƒ…')
    parser.add_argument('--clean-completed', action='store_true', help='æ¸…ç†å·²å®Œæˆçš„ä»»åŠ¡')
    parser.add_argument('--clean-failed', action='store_true', help='æ¸…ç†å¤±è´¥çš„ä»»åŠ¡')
    parser.add_argument('--fix-progress', action='store_true', help='ä¿®å¤è¿›åº¦æ˜¾ç¤ºé—®é¢˜')

    # ä¸‹è½½å‚æ•°
    parser.add_argument('--output-dir', type=str, help='ä¸‹è½½è¾“å‡ºç›®å½•')
    parser.add_argument('--base-url', type=str, help='åŸºç¡€URL (é»˜è®¤: https://hf-mirror.com)')
    parser.add_argument('--dataset', action='store_true', help='ä¸‹è½½æ•°æ®é›† (é»˜è®¤ä¸‹è½½æ¨¡å‹)')
    parser.add_argument('--tool', choices=['aria2c', 'wget'], help='ä¸‹è½½å·¥å…·')
    parser.add_argument('--threads', type=int, help='å¹¶å‘çº¿ç¨‹æ•°')
    parser.add_argument('--exclude', nargs='*', help='æ’é™¤æ–‡ä»¶æ¨¡å¼')
    parser.add_argument('--include', nargs='*', help='åŒ…å«æ–‡ä»¶æ¨¡å¼')
    
    # ç³»ç»Ÿç®¡ç†å‚æ•°
    parser.add_argument('--check-system', action='store_true', help='æ£€æŸ¥ç³»ç»ŸçŠ¶æ€')
    parser.add_argument('--verify', action='store_true', help='éªŒè¯å·²ä¸‹è½½æ–‡ä»¶çš„å®Œæ•´æ€§')
    
    # æ‰¹é‡æ“ä½œå‚æ•°  
    parser.add_argument('--batch-file', type=str, help='æ‰¹é‡ä¸‹è½½é…ç½®æ–‡ä»¶')
    parser.add_argument('--batch-create', action='store_true', help='æ‰¹é‡åˆ›å»ºä»»åŠ¡')
    parser.add_argument('--batch-start', action='store_true', help='æ‰¹é‡å¼€å§‹ä¸‹è½½')
    parser.add_argument('--batch-status', action='store_true', help='æ‰¹é‡çŠ¶æ€æŸ¥è¯¢')
    parser.add_argument('--batch-stop', action='store_true', help='æ‰¹é‡åœæ­¢ä¸‹è½½')
    
    # é…ç½®å‚æ•°
    parser.add_argument('--config', type=str, default='config.json', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # æ·»åŠ æ•°æ®é›†å‘½ä»¤
    add_parser = subparsers.add_parser('add-dataset', help='æ·»åŠ æ•°æ®é›†ä¿¡æ¯')
    add_parser.add_argument('repo_id', help='æ•°æ®é›†ä»“åº“ID (å¦‚: gpt2, bigscience/bloom-560m)')
    add_parser.add_argument('--description', help='æ•°æ®é›†æè¿°')
    add_parser.add_argument('--dataset', action='store_true', help='æ ‡è®°ä¸ºæ•°æ®é›†ï¼ˆé»˜è®¤ä¸ºæ¨¡å‹ï¼‰')
    add_parser.add_argument('--tags', nargs='*', help='æ ‡ç­¾åˆ—è¡¨')
    
    # HFDå¯¼å…¥å‘½ä»¤
    import_parser = subparsers.add_parser('import-hfd', help='å¯¼å…¥HFDä¸‹è½½çš„ä»»åŠ¡')
    import_parser.add_argument('hfd_dir', help='HFDç›®å½•è·¯å¾„ï¼ˆåŒ…å«.hfdå­ç›®å½•ï¼Œæˆ–ç›´æ¥æŒ‡å‘.hfdç›®å½•ï¼‰')
    import_parser.add_argument('output_dir', help='æ•°æ®é›†è¾“å‡ºç›®å½•ï¼ˆæ–‡ä»¶çš„å®é™…ä½ç½®ï¼‰')
    import_parser.add_argument('--base-url', default='https://hf-mirror.com', help='åŸºç¡€URL (é»˜è®¤: https://hf-mirror.com)')
    import_parser.add_argument('--dry-run', action='store_true', help='åªæ˜¾ç¤ºæ‘˜è¦ï¼Œä¸å®é™…å¯¼å…¥')
    
    # ä¸‹è½½å‘½ä»¤
    download_parser = subparsers.add_parser('download', help='ä¸‹è½½æ•°æ®é›†/æ¨¡å‹')
    download_parser.add_argument('repo_id', help='è¦ä¸‹è½½çš„æ•°æ®é›†/æ¨¡å‹ID')
    download_parser.add_argument('--local-dir', help='æœ¬åœ°ä¸‹è½½ç›®å½•')
    download_parser.add_argument('--revision', default='main', help='ç‰ˆæœ¬/åˆ†æ”¯')
    download_parser.add_argument('--dataset', action='store_true', help='æ ‡è®°ä¸ºæ•°æ®é›†ï¼ˆè€Œéæ¨¡å‹ï¼‰')
    
    # ä»»åŠ¡ç®¡ç†å‘½ä»¤
    subparsers.add_parser('list-datasets', help='åˆ—å‡ºæ‰€æœ‰æ•°æ®é›†')
    
    status_parser = subparsers.add_parser('status', help='æŸ¥çœ‹ä»»åŠ¡çŠ¶æ€')
    status_parser.add_argument('task_id', help='ä»»åŠ¡ID')
    
    cancel_parser = subparsers.add_parser('cancel', help='å–æ¶ˆä»»åŠ¡')
    cancel_parser.add_argument('task_id', help='ä»»åŠ¡ID')
    
    resume_parser = subparsers.add_parser('resume', help='æ¢å¤ä»»åŠ¡')
    resume_parser.add_argument('task_id', help='ä»»åŠ¡ID')
    resume_parser.add_argument('--skip-moved-files', action='store_true', 
                              help='è‡ªåŠ¨è·³è¿‡å·²å®Œæˆä½†è¢«ç§»èµ°çš„æ–‡ä»¶ï¼ˆé»˜è®¤è¡Œä¸ºï¼‰')
    resume_parser.add_argument('--redownload-moved-files', action='store_true',
                              help='é‡æ–°ä¸‹è½½å·²å®Œæˆä½†è¢«ç§»èµ°çš„æ–‡ä»¶')
    
    # æ¸…ç†å‘½ä»¤  
    subparsers.add_parser('clean', help='æ¸…ç†å®Œæˆçš„ä»»åŠ¡è®°å½•')
    
    # ä¿®å¤è¿›åº¦å‘½ä»¤
    subparsers.add_parser('fix-progress', help='ä¿®å¤å·²å®Œæˆä»»åŠ¡çš„è¿›åº¦æ˜¾ç¤º')
    
    # ç³»ç»Ÿæ£€æŸ¥å‘½ä»¤
    check_parser = subparsers.add_parser('check-system', help='æ£€æŸ¥ç³»ç»ŸçŠ¶æ€')
    check_parser.add_argument('--path', default='.', help='æ£€æŸ¥è·¯å¾„ï¼ˆé»˜è®¤å½“å‰ç›®å½•ï¼‰')
    check_parser.add_argument('--size', type=int, default=0, help='é¢„è®¡ä¸‹è½½å¤§å°ï¼ˆå­—èŠ‚ï¼‰')
    
    # æ–‡ä»¶éªŒè¯å‘½ä»¤
    verify_parser = subparsers.add_parser('verify', help='éªŒè¯ä¸‹è½½æ–‡ä»¶å®Œæ•´æ€§')
    verify_parser.add_argument('task_id', help='ä»»åŠ¡ID')
    
    # è¯¦ç»†ä»»åŠ¡ä¿¡æ¯å‘½ä»¤
    detail_parser = subparsers.add_parser('task-detail', help='æŸ¥çœ‹ä»»åŠ¡è¯¦ç»†ä¿¡æ¯')
    detail_parser.add_argument('task_id', help='ä»»åŠ¡ID')
    
    # é…ç½®ä¿¡æ¯å‘½ä»¤
    subparsers.add_parser('config', help='æ˜¾ç¤ºå½“å‰é…ç½®ä¿¡æ¯')
    
    # åˆ†æ‰¹ä¸‹è½½ç›¸å…³å‘½ä»¤
    analyze_parser = subparsers.add_parser('analyze-dataset', help='åˆ†ææ•°æ®é›†å¤§å°å’Œç»“æ„')
    analyze_parser.add_argument('repo_id', help='æ•°æ®é›†ä»“åº“ID')
    analyze_parser.add_argument('--dataset', action='store_true', help='æ ‡è®°ä¸ºæ•°æ®é›†')
    analyze_parser.add_argument('--quick', action='store_true', help='å¿«é€Ÿæ¨¡å¼ï¼Œä½¿ç”¨é‡‡æ ·åˆ†æï¼ˆé€‚ç”¨äºå¤§æ•°æ®é›†ï¼‰')
    analyze_parser.add_argument('--sample-size', type=int, default=100, help='å¿«é€Ÿæ¨¡å¼çš„é‡‡æ ·æ–‡ä»¶æ•°é‡ï¼ˆé»˜è®¤100ï¼‰')
    analyze_parser.add_argument('--timeout', type=int, default=30, help='è·å–æ–‡ä»¶åˆ—è¡¨çš„è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤30ï¼‰')
    
    plan_parser = subparsers.add_parser('plan-batch', help='è§„åˆ’åˆ†æ‰¹ä¸‹è½½ç­–ç•¥')
    plan_parser.add_argument('repo_id', help='æ•°æ®é›†ä»“åº“ID') 
    plan_parser.add_argument('--available-space', type=int, required=True, help='å¯ç”¨ç©ºé—´ï¼ˆå­—èŠ‚ï¼‰')
    plan_parser.add_argument('--dataset', action='store_true', help='æ ‡è®°ä¸ºæ•°æ®é›†')
    plan_parser.add_argument('--safety-margin', type=float, default=0.9, help='å®‰å…¨ä½™é‡æ¯”ä¾‹ï¼ˆé»˜è®¤0.9ï¼‰')
    
    batch_download_parser = subparsers.add_parser('batch-download', help='æ‰§è¡Œåˆ†æ‰¹ä¸‹è½½')
    batch_download_parser.add_argument('repo_id', help='æ•°æ®é›†ä»“åº“ID')
    batch_download_parser.add_argument('--available-space', type=int, required=True, help='å¯ç”¨ç©ºé—´ï¼ˆå­—èŠ‚ï¼‰')
    batch_download_parser.add_argument('--dataset', action='store_true', help='æ ‡è®°ä¸ºæ•°æ®é›†')
    batch_download_parser.add_argument('--auto-proceed', action='store_true', help='è‡ªåŠ¨ç»§ç»­ä¸‹ä¸€æ‰¹æ¬¡')
    batch_download_parser.add_argument('--tool', choices=['aria2c', 'wget'], default='aria2c', help='ä¸‹è½½å·¥å…·')
    
    batch_continue_parser = subparsers.add_parser('batch-continue', help='ç»§ç»­åˆ†æ‰¹ä¸‹è½½')
    batch_continue_parser.add_argument('task_id', help='ä»»åŠ¡ID')
    batch_continue_parser.add_argument('batch_number', type=int, help='ç»§ç»­çš„æ‰¹æ¬¡å·')
    
    batch_status_parser = subparsers.add_parser('batch-status', help='æŸ¥çœ‹åˆ†æ‰¹ä¸‹è½½çŠ¶æ€')
    batch_status_parser.add_argument('task_id', help='ä»»åŠ¡ID')
    
    delete_parser = subparsers.add_parser('delete-task', help='åˆ é™¤ä»»åŠ¡')
    delete_parser.add_argument('task_id', help='ä»»åŠ¡ID')
    delete_parser.add_argument('--force', action='store_true', help='å¼ºåˆ¶åˆ é™¤ï¼Œä¸è¯¢é—®ç¡®è®¤')
    delete_parser.add_argument('--keep-files', action='store_true', help='ä¿ç•™ä¸‹è½½çš„æ–‡ä»¶ï¼Œåªåˆ é™¤ä»»åŠ¡è®°å½•')
    
    cleanup_parser = subparsers.add_parser('cleanup', help='æ¸…ç†æ‰€æœ‰ä»»åŠ¡')
    cleanup_parser.add_argument('--status', choices=['completed', 'failed', 'running', 'cancelled'], 
                               help='åªæ¸…ç†æŒ‡å®šçŠ¶æ€çš„ä»»åŠ¡')
    cleanup_parser.add_argument('--force', action='store_true', help='å¼ºåˆ¶æ¸…ç†ï¼Œä¸è¯¢é—®ç¡®è®¤')
    cleanup_parser.add_argument('--keep-files', action='store_true', help='ä¿ç•™ä¸‹è½½çš„æ–‡ä»¶ï¼Œåªåˆ é™¤ä»»åŠ¡è®°å½•')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    # åˆå§‹åŒ–é…ç½®
    config = get_config()
    
    # å¤„ç†HFè®¤è¯å‚æ•°
    if hasattr(args, 'hf_username') and args.hf_username:
        config.set_hf_auth(username=args.hf_username)
    if hasattr(args, 'hf_token') and args.hf_token:
        config.set_hf_auth(token=args.hf_token)
    
    # ä¿å­˜é…ç½®æ›´æ–°
    if (hasattr(args, 'hf_username') and args.hf_username) or (hasattr(args, 'hf_token') and args.hf_token):
        config.save_config()
        print("âœ… HFè®¤è¯ä¿¡æ¯å·²ä¿å­˜åˆ°é…ç½®æ–‡ä»¶")
    
    # æ£€æŸ¥å¹¶æ˜¾ç¤ºè®¤è¯çŠ¶æ€
    if config.is_hf_auth_available():
        username, token = config.get_hf_auth()
        print(f"ğŸ” HFè®¤è¯: ç”¨æˆ·å={username or 'N/A'}, Token={'å·²è®¾ç½®' if token else 'æœªè®¾ç½®'}")
    
    # è®¾ç½®é…ç½®è·¯å¾„
    if hasattr(args, 'metadata_dir') and args.metadata_dir:
        config.set('paths.metadata_dir', args.metadata_dir)
    if hasattr(args, 'downloads_dir') and args.downloads_dir:
        config.set('paths.downloads_dir', args.downloads_dir)  
    if hasattr(args, 'logs_dir') and args.logs_dir:
        config.set('paths.logs_dir', args.logs_dir)
    
    # è®¾ç½®HFç«¯ç‚¹
    if hasattr(args, 'base_url') and args.base_url:
        config.set('network.hf_endpoint', args.base_url)
    
    # è®¾ç½®æ—¥å¿—
    setup_logging()
    
    # åˆå§‹åŒ–ç®¡ç†å™¨
    dataset_manager = DatasetManager()
    download_manager = DownloadManager()
    task_manager = TaskManager()
    system_monitor = SystemMonitor()
    batch_manager = BatchDownloadManager()
    
    try:
        if args.command == 'add-dataset':
            dataset_manager.add_dataset(
                repo_id=args.repo_id,
                description=args.description,
                is_dataset=args.dataset,
                tags=args.tags or []
            )
            print(f"{Colors.GREEN}âœ“ æ•°æ®é›† '{args.repo_id}' æ·»åŠ æˆåŠŸ{Colors.NC}")
            
        elif args.command == 'import-hfd':
            # å¯¼å…¥ HFD ä»»åŠ¡
            try:
                from hfd_importer import HFDImporter
                
                # æŸ¥æ‰¾ .hfd ç›®å½•
                hfd_dir = Path(args.hfd_dir)
                if hfd_dir.name == '.hfd':
                    hfd_metadata_dir = hfd_dir
                else:
                    hfd_metadata_dir = hfd_dir / '.hfd'
                    
                if not hfd_metadata_dir.exists():
                    print(f"{Colors.RED}âŒ é”™è¯¯: æ‰¾ä¸åˆ° .hfd ç›®å½•: {hfd_metadata_dir}{Colors.NC}")
                    return
                    
                # åˆ›å»ºå¯¼å…¥å™¨
                importer = HFDImporter(
                    hfd_dir=str(hfd_metadata_dir),
                    output_dir=args.output_dir,
                    base_url=args.base_url
                )
                
                # æ˜¾ç¤ºæ‘˜è¦
                print(f"{Colors.BLUE}æ­£åœ¨åˆ†æ HFD ä»»åŠ¡...{Colors.NC}")
                importer.print_summary()
                
                if args.dry_run:
                    print(f"\n{Colors.CYAN}ğŸ” è¿™æ˜¯è¯•è¿è¡Œæ¨¡å¼ï¼Œæœªå®é™…å¯¼å…¥æ•°æ®{Colors.NC}")
                    return
                    
                # ç¡®è®¤å¯¼å…¥
                print(f"\n{Colors.YELLOW}â“ æ˜¯å¦è¦å°†è¿™ä¸ª HFD ä»»åŠ¡å¯¼å…¥åˆ°æ•°æ®åº“ï¼Ÿ (y/N): {Colors.NC}", end='')
                response = input().strip().lower()
                
                if response in ['y', 'yes']:
                    # æ‰§è¡Œå¯¼å…¥
                    print(f"{Colors.BLUE}æ­£åœ¨å¯¼å…¥ä»»åŠ¡...{Colors.NC}")
                    task_id = importer.import_to_system(task_manager)
                    
                    print(f"\n{Colors.GREEN}âœ… å¯¼å…¥æˆåŠŸï¼{Colors.NC}")
                    print(f"{Colors.CYAN}ğŸ“‹ ä»»åŠ¡ID: {task_id}{Colors.NC}")
                    print(f"{Colors.CYAN}ğŸ’¾ ä»»åŠ¡æ–‡ä»¶: {task_manager.tasks_file}{Colors.NC}")
                    print(f"\n{Colors.BLUE}ğŸš€ ä½ ç°åœ¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ç»§ç»­ä¸‹è½½:{Colors.NC}")
                    print(f"   {Colors.NC}python main.py resume {task_id}{Colors.NC}")
                    print(f"   {Colors.NC}python main.py status {task_id}{Colors.NC}")
                    
                else:
                    print(f"\n{Colors.YELLOW}âŒ å¯¼å…¥å·²å–æ¶ˆ{Colors.NC}")
                    
            except ImportError:
                print(f"{Colors.RED}âŒ é”™è¯¯: æ— æ³•å¯¼å…¥ HFDImporterï¼Œè¯·æ£€æŸ¥æ¨¡å—{Colors.NC}")
            except Exception as e:
                print(f"{Colors.RED}âŒ å¯¼å…¥å¤±è´¥: {e}{Colors.NC}")
                
        elif args.command == 'download':
            # æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è‡ªåŠ¨æ·»åŠ 
            if not dataset_manager.get_dataset(args.repo_id):
                print(f"{Colors.YELLOW}æ•°æ®é›† '{args.repo_id}' ä¸å­˜åœ¨ï¼Œè‡ªåŠ¨æ·»åŠ ...{Colors.NC}")
                dataset_manager.add_dataset(args.repo_id, is_dataset=getattr(args, 'dataset', False))
            
            task_id = task_manager.create_task(
                repo_id=args.repo_id,
                local_dir=args.local_dir,
                revision=args.revision,
                is_dataset=getattr(args, 'dataset', False)
            )
            
            print(f"{Colors.GREEN}âœ“ ä¸‹è½½ä»»åŠ¡å·²åˆ›å»ºï¼Œä»»åŠ¡ID: {task_id}{Colors.NC}")
            print(f"{Colors.YELLOW}å¼€å§‹ä¸‹è½½...{Colors.NC}")
            
            # å¼€å§‹ä¸‹è½½
            success = download_manager.start_download(task_id)
            if success:
                # ç­‰å¾…ä¸‹è½½å®Œæˆ - æ·»åŠ è¶…æ—¶å’Œæ›´å¥½çš„çŠ¶æ€æ£€æµ‹
                max_iterations = 300  # æœ€å¤šç­‰å¾…10åˆ†é’Ÿï¼ˆ300 * 2ç§’ï¼‰
                iteration = 0
                
                while iteration < max_iterations:
                    # é‡æ–°åŠ è½½ä»»åŠ¡æ•°æ®ï¼Œç¡®ä¿è·å–æœ€æ–°çŠ¶æ€
                    task_manager.tasks = task_manager._load_tasks()
                    task = task_manager.get_task(task_id)
                    
                    if not task:
                        print(f"{Colors.RED}âœ— ä»»åŠ¡ {task_id} ä¸å­˜åœ¨{Colors.NC}")
                        break
                        
                    if task['status'] in ['completed', 'failed', 'cancelled']:
                        break
                        
                    print(f"{Colors.BLUE}ä¸‹è½½ä¸­... è¿›åº¦: {task.get('progress', '0%')} | çŠ¶æ€: {task['status']}{Colors.NC}")
                    time.sleep(2)
                    iteration += 1
                
                # æœ€ç»ˆçŠ¶æ€æ£€æŸ¥
                task_manager.tasks = task_manager._load_tasks()
                final_task = task_manager.get_task(task_id)
                
                if not final_task:
                    print(f"{Colors.RED}âœ— ä»»åŠ¡ä¸¢å¤±{Colors.NC}")
                elif iteration >= max_iterations:
                    print(f"{Colors.YELLOW}âš  ä¸‹è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ä»»åŠ¡çŠ¶æ€{Colors.NC}")
                elif final_task['status'] == 'completed':
                    print(f"{Colors.GREEN}âœ“ ä¸‹è½½å®Œæˆ{Colors.NC}")
                else:
                    print(f"{Colors.RED}âœ— ä¸‹è½½å¤±è´¥: {final_task.get('error_message', 'æœªçŸ¥é”™è¯¯')}{Colors.NC}")
            else:
                print(f"{Colors.RED}âœ— ä¸‹è½½å¯åŠ¨å¤±è´¥{Colors.NC}")
                
        elif args.command == 'list-tasks':
            tasks = task_manager.list_tasks()
            if not tasks:
                print(f"{Colors.YELLOW}æš‚æ— ä»»åŠ¡{Colors.NC}")
            else:
                print(f"\n{'ID':<8} {'æ•°æ®é›†':<30} {'çŠ¶æ€':<10} {'å·¥å…·':<8} {'è¿›åº¦':<10} {'åˆ›å»ºæ—¶é—´':<20}")
                print("-" * 90)
                for task in tasks:
                    status_color = {
                        'pending': Colors.YELLOW,
                        'running': Colors.BLUE,
                        'completed': Colors.GREEN,
                        'failed': Colors.RED,
                        'cancelled': Colors.GRAY
                    }.get(task['status'], Colors.NC)
                    
                    print(f"{task['id']:<8} {task['repo_id']:<30} {status_color}{task['status']:<10}{Colors.NC} "
                          f"{task['tool']:<8} {task.get('progress', 'N/A'):<10} {task['created_at'][:16]:<20}")
                    
        elif args.command == 'list-datasets':
            datasets = dataset_manager.list_datasets()
            if not datasets:
                print(f"{Colors.YELLOW}æš‚æ— æ•°æ®é›†{Colors.NC}")
            else:
                print(f"\n{'ä»“åº“ID':<40} {'ç±»å‹':<8} {'æè¿°':<50}")
                print("-" * 100)
                for ds in datasets:
                    ds_type = "æ•°æ®é›†" if ds.get('is_dataset') else "æ¨¡å‹"
                    desc = ds.get('description', '')[:47] + '...' if len(ds.get('description', '')) > 50 else ds.get('description', '')
                    print(f"{ds['repo_id']:<40} {ds_type:<8} {desc:<50}")
                    
        elif args.command == 'status':
            task = task_manager.get_task(args.task_id)
            if not task:
                print(f"{Colors.RED}âœ— ä»»åŠ¡ {args.task_id} ä¸å­˜åœ¨{Colors.NC}")
                return
                
            print(f"\nä»»åŠ¡è¯¦æƒ…:")
            print(f"ID: {task['id']}")
            print(f"æ•°æ®é›†: {task['repo_id']}")
            print(f"çŠ¶æ€: {task['status']}")
            print(f"å·¥å…·: {task['tool']}")
            print(f"åˆ›å»ºæ—¶é—´: {task['created_at']}")
            if task.get('completed_at'):
                print(f"å®Œæˆæ—¶é—´: {task['completed_at']}")
            if task.get('error_message'):
                print(f"é”™è¯¯ä¿¡æ¯: {task['error_message']}")
                
        elif args.command == 'cancel':
            success = task_manager.cancel_task(args.task_id)
            if success:
                print(f"{Colors.GREEN}âœ“ ä»»åŠ¡ {args.task_id} å·²å–æ¶ˆ{Colors.NC}")
            else:
                print(f"{Colors.RED}âœ— æ— æ³•å–æ¶ˆä»»åŠ¡ {args.task_id}{Colors.NC}")
                
        elif args.command == 'resume':
            # è·å–ä»»åŠ¡ä¿¡æ¯
            task = task_manager.get_task(args.task_id)
            if not task:
                print(f"{Colors.RED}âœ— ä»»åŠ¡ {args.task_id} ä¸å­˜åœ¨{Colors.NC}")
                return
            
            # æ£€æŸ¥å‚æ•°å†²çª
            if args.skip_moved_files and args.redownload_moved_files:
                print(f"{Colors.RED}âœ— --skip-moved-files å’Œ --redownload-moved-files ä¸èƒ½åŒæ—¶ä½¿ç”¨{Colors.NC}")
                return
            
            print(f"{Colors.BLUE}å‡†å¤‡æ¢å¤ä¸‹è½½ä»»åŠ¡:{Colors.NC}")
            print(f"  ID: {args.task_id}")
            print(f"  æ•°æ®é›†: {task['repo_id']}")
            print(f"  å½“å‰çŠ¶æ€: {task['status']}")
            print(f"  å½“å‰è¿›åº¦: {task.get('progress', '0%')}")
            
            # æ˜¾ç¤ºç§»èµ°æ–‡ä»¶å¤„ç†ç­–ç•¥
            if args.redownload_moved_files:
                print(f"  ç§»èµ°æ–‡ä»¶ç­–ç•¥: {Colors.YELLOW}é‡æ–°ä¸‹è½½å·²ç§»èµ°çš„æ–‡ä»¶{Colors.NC}")
            else:
                print(f"  ç§»èµ°æ–‡ä»¶ç­–ç•¥: {Colors.GREEN}è·³è¿‡å·²ç§»èµ°çš„æ–‡ä»¶ï¼ˆæ¨èï¼‰{Colors.NC}")
            
            # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
            if task['status'] == 'completed':
                print(f"{Colors.GREEN}ä»»åŠ¡å·²å®Œæˆï¼Œæ— éœ€æ¢å¤{Colors.NC}")
                
                # ä½†æ˜¯è®©ç”¨æˆ·é€‰æ‹©æ˜¯å¦è¦é‡æ–°éªŒè¯æ–‡ä»¶
                response = input("æ˜¯å¦è¦é‡æ–°éªŒè¯æ–‡ä»¶å®Œæ•´æ€§ï¼Ÿ(y/N): ")
                if response.lower() == 'y':
                    print(f"{Colors.YELLOW}æ­£åœ¨é‡æ–°éªŒè¯æ–‡ä»¶...{Colors.NC}")
                    # é‡ç½®ä»»åŠ¡çŠ¶æ€ä¸ºpendingï¼Œè®©ç³»ç»Ÿé‡æ–°æ£€æŸ¥
                    task_manager.update_task_status(args.task_id, 'pending')
                else:
                    return
            elif task['status'] == 'running':
                print(f"{Colors.YELLOW}âš ï¸ ä»»åŠ¡æ˜¾ç¤ºä¸ºè¿è¡Œä¸­ï¼Œä½†å¯èƒ½å·²ä¸­æ–­{Colors.NC}")
                response = input("æ˜¯å¦å¼ºåˆ¶é‡æ–°å¼€å§‹ä¸‹è½½ï¼Ÿ(y/N): ")
                if response.lower() != 'y':
                    print("å–æ¶ˆæ¢å¤")
                    return
                # é‡ç½®ä»»åŠ¡çŠ¶æ€ä¸ºpending
                task_manager.update_task_status(args.task_id, 'pending')
            else:
                # å¯¹äºå…¶ä»–çŠ¶æ€ï¼ˆfailed, cancelledç­‰ï¼‰ï¼Œç›´æ¥é‡ç½®ä¸ºpending
                task_manager.update_task_status(args.task_id, 'pending')
            
            print(f"{Colors.YELLOW}æ­£åœ¨æ¢å¤ä¸‹è½½...{Colors.NC}")
            
            # è®¾ç½®ç§»èµ°æ–‡ä»¶å¤„ç†é€‰é¡¹
            download_manager.set_moved_files_strategy(
                'redownload' if args.redownload_moved_files else 'skip'
            )
            
            # å¼€å§‹ä¸‹è½½ï¼ˆæ”¯æŒæ™ºèƒ½æ–­ç‚¹ç»­ä¼ ï¼‰
            success = download_manager.start_download(args.task_id)
            if success:
                print(f"{Colors.GREEN}âœ“ ä¸‹è½½æ¢å¤æˆåŠŸ{Colors.NC}")
                
                # ç­‰å¾…ä¸‹è½½å®Œæˆ
                max_iterations = 300  # æœ€å¤šç­‰å¾…10åˆ†é’Ÿ
                iteration = 0
                
                while iteration < max_iterations:
                    # é‡æ–°åŠ è½½ä»»åŠ¡æ•°æ®
                    task_manager.tasks = task_manager._load_tasks()
                    current_task = task_manager.get_task(args.task_id)
                    
                    if not current_task:
                        print(f"{Colors.RED}âœ— ä»»åŠ¡ä¸¢å¤±{Colors.NC}")
                        break
                        
                    if current_task['status'] in ['completed', 'failed', 'cancelled']:
                        break
                        
                    print(f"{Colors.BLUE}ä¸‹è½½ä¸­... è¿›åº¦: {current_task.get('progress', '0%')} | çŠ¶æ€: {current_task['status']}{Colors.NC}")
                    time.sleep(2)
                    iteration += 1
                
                # æœ€ç»ˆçŠ¶æ€æ£€æŸ¥
                task_manager.tasks = task_manager._load_tasks()
                final_task = task_manager.get_task(args.task_id)
                
                if not final_task:
                    print(f"{Colors.RED}âœ— ä»»åŠ¡ä¸¢å¤±{Colors.NC}")
                elif iteration >= max_iterations:
                    print(f"{Colors.YELLOW}âš  ä¸‹è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ä»»åŠ¡çŠ¶æ€{Colors.NC}")
                elif final_task['status'] == 'completed':
                    print(f"{Colors.GREEN}âœ“ æ¢å¤ä¸‹è½½å®Œæˆ{Colors.NC}")
                else:
                    print(f"{Colors.RED}âœ— æ¢å¤ä¸‹è½½å¤±è´¥: {final_task.get('error_message', 'æœªçŸ¥é”™è¯¯')}{Colors.NC}")
            else:
                print(f"{Colors.RED}âœ— æ— æ³•æ¢å¤ä»»åŠ¡ {args.task_id}{Colors.NC}")
                
        elif args.command == 'clean':
            count = task_manager.clean_completed_tasks()
            print(f"{Colors.GREEN}âœ“ å·²æ¸…ç† {count} ä¸ªå®Œæˆçš„ä»»åŠ¡è®°å½•{Colors.NC}")
            
        elif args.command == 'fix-progress':
            # ä¿®å¤å·²å®Œæˆä»»åŠ¡çš„è¿›åº¦æ˜¾ç¤º
            tasks = task_manager.list_tasks(status='completed')
            fixed_count = 0
            
            for task in tasks:
                if task.get('progress', '0%') != '100%':
                    task_manager.update_task_progress(task['id'], '100%')
                    fixed_count += 1
                    print(f"{Colors.YELLOW}ä¿®å¤ä»»åŠ¡ {task['id']} ({task['repo_id']}) è¿›åº¦: {task.get('progress')} -> 100%{Colors.NC}")
            
            if fixed_count > 0:
                print(f"{Colors.GREEN}âœ“ å·²ä¿®å¤ {fixed_count} ä¸ªä»»åŠ¡çš„è¿›åº¦æ˜¾ç¤º{Colors.NC}")
            else:
                print(f"{Colors.YELLOW}æ²¡æœ‰éœ€è¦ä¿®å¤çš„ä»»åŠ¡{Colors.NC}")
                
        elif args.command == 'check-system':
            # ç³»ç»Ÿæ£€æŸ¥
            print(f"{Colors.BLUE}æ­£åœ¨æ£€æŸ¥ç³»ç»ŸçŠ¶æ€...{Colors.NC}")
            check_result = system_monitor.comprehensive_check(args.path, args.size)
            system_status_ok = system_monitor.print_system_status(check_result)
            
            if not system_status_ok:
                print(f"\n{Colors.RED}âš  ç³»ç»Ÿæ£€æŸ¥å‘ç°é—®é¢˜ï¼Œå»ºè®®è§£å†³åå†è¿›è¡Œä¸‹è½½{Colors.NC}")
                sys.exit(1)
            else:
                print(f"\n{Colors.GREEN}âœ“ ç³»ç»ŸçŠ¶æ€æ­£å¸¸ï¼Œå¯ä»¥è¿›è¡Œä¸‹è½½{Colors.NC}")
                
        elif args.command == 'verify':
            # éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
            task = task_manager.get_task(args.task_id)
            if not task:
                print(f"{Colors.RED}âœ— ä»»åŠ¡ {args.task_id} ä¸å­˜åœ¨{Colors.NC}")
                return
            
            try:
                file_tracker = FileTracker(args.task_id)
                
                # ç¡®å®šä¸‹è½½è·¯å¾„
                if task.get('local_dir'):
                    download_path = Path(task['local_dir'])
                else:
                    download_path = Path('downloads') / task['repo_id']
                
                print(f"{Colors.YELLOW}æ­£åœ¨éªŒè¯ä»»åŠ¡ {args.task_id} çš„æ–‡ä»¶å®Œæ•´æ€§...{Colors.NC}")
                integrity_results = file_tracker.verify_file_integrity(download_path)
                
                # ç»Ÿè®¡ç»“æœ
                total_files = len(integrity_results)
                valid_files = len([r for r in integrity_results.values() if r['status'] == 'valid'])
                missing_files = len([r for r in integrity_results.values() if not r['exists']])
                mismatch_files = len([r for r in integrity_results.values() if r['exists'] and not r['size_match']])
                
                print(f"\n{Colors.BOLD}=== æ–‡ä»¶å®Œæ•´æ€§éªŒè¯ç»“æœ ==={Colors.NC}")
                print(f"æ€»æ–‡ä»¶æ•°: {total_files}")
                print(f"å®Œæ•´æ–‡ä»¶: {Colors.GREEN}{valid_files}{Colors.NC}")
                print(f"ç¼ºå¤±æ–‡ä»¶: {Colors.RED}{missing_files}{Colors.NC}")
                print(f"å¤§å°ä¸åŒ¹é…: {Colors.YELLOW}{mismatch_files}{Colors.NC}")
                
                # æ˜¾ç¤ºé—®é¢˜æ–‡ä»¶è¯¦æƒ…
                problem_files = [(f, r) for f, r in integrity_results.items() if r['status'] != 'valid']
                if problem_files:
                    print(f"\n{Colors.RED}é—®é¢˜æ–‡ä»¶è¯¦æƒ…:{Colors.NC}")
                    for filename, result in problem_files[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                        if not result['exists']:
                            print(f"  âœ— {filename}: æ–‡ä»¶ç¼ºå¤±")
                        elif not result['size_match']:
                            print(f"  âš  {filename}: å¤§å°ä¸åŒ¹é… (å®é™…: {result['actual_size']}, æœŸæœ›: {result['expected_size']})")
                    
                    if len(problem_files) > 10:
                        print(f"  ... è¿˜æœ‰ {len(problem_files) - 10} ä¸ªé—®é¢˜æ–‡ä»¶")
                else:
                    print(f"\n{Colors.GREEN}âœ“ æ‰€æœ‰æ–‡ä»¶éªŒè¯é€šè¿‡{Colors.NC}")
                    
            except Exception as e:
                print(f"{Colors.RED}âœ— éªŒè¯å¤±è´¥: {str(e)}{Colors.NC}")
                
        elif args.command == 'task-detail':
            # æŸ¥çœ‹ä»»åŠ¡è¯¦ç»†ä¿¡æ¯
            task = task_manager.get_task(args.task_id)
            if not task:
                print(f"{Colors.RED}âœ— ä»»åŠ¡ {args.task_id} ä¸å­˜åœ¨{Colors.NC}")
                return
            
            try:
                file_tracker = FileTracker(args.task_id)
                summary = file_tracker.get_download_summary()
                failed_files = file_tracker.get_failed_files()
                pending_files = file_tracker.get_pending_files()
                
                print(f"\n{Colors.BOLD}=== ä»»åŠ¡è¯¦ç»†ä¿¡æ¯ ==={Colors.NC}")
                print(f"ä»»åŠ¡ID: {task['id']}")
                print(f"ä»“åº“: {task['repo_id']}")
                print(f"çŠ¶æ€: {task['status']}")
                print(f"å·¥å…·: {task['tool']}")
                print(f"åˆ›å»ºæ—¶é—´: {task['created_at']}")
                if task.get('completed_at'):
                    print(f"å®Œæˆæ—¶é—´: {task['completed_at']}")
                if task.get('error_message'):
                    print(f"é”™è¯¯ä¿¡æ¯: {task['error_message']}")
                
                print(f"\n{Colors.BOLD}=== æ–‡ä»¶ç»Ÿè®¡ ==={Colors.NC}")
                print(f"æ€»æ–‡ä»¶æ•°: {summary['total_files']}")
                print(f"å·²å®Œæˆ: {summary['completed_files']} ({summary['completion_rate']})")
                print(f"å¤±è´¥: {summary['failed_files']}")
                print(f"å¾…ä¸‹è½½: {summary['pending_files']}")
                print(f"ä¸‹è½½å¤§å°: {summary['downloaded_size_formatted']} / {summary['total_size_formatted']}")
                
                # æ˜¾ç¤ºå¤±è´¥çš„æ–‡ä»¶
                if failed_files:
                    print(f"\n{Colors.RED}å¤±è´¥æ–‡ä»¶:{Colors.NC}")
                    for file_info in failed_files[:5]:
                        print(f"  âœ— {file_info['filename']}: {file_info['error']}")
                    if len(failed_files) > 5:
                        print(f"  ... è¿˜æœ‰ {len(failed_files) - 5} ä¸ªå¤±è´¥æ–‡ä»¶")
                
                # æ˜¾ç¤ºå¾…ä¸‹è½½çš„æ–‡ä»¶
                if pending_files:
                    print(f"\n{Colors.YELLOW}å¾…ä¸‹è½½æ–‡ä»¶:{Colors.NC}")
                    for file_info in pending_files[:5]:
                        size_str = f" ({format_file_size(file_info['size'])})" if file_info['size'] > 0 else ""
                        print(f"  â—‹ {file_info['filename']}{size_str}")
                    if len(pending_files) > 5:
                        print(f"  ... è¿˜æœ‰ {len(pending_files) - 5} ä¸ªå¾…ä¸‹è½½æ–‡ä»¶")
                        
            except Exception as e:
                print(f"{Colors.YELLOW}æ— æ³•è·å–è¯¦ç»†æ–‡ä»¶ä¿¡æ¯: {str(e)}{Colors.NC}")
                # è‡³å°‘æ˜¾ç¤ºåŸºæœ¬ä»»åŠ¡ä¿¡æ¯
                print(f"\nä»»åŠ¡è¯¦æƒ…:")
                print(f"ID: {task['id']}")
                print(f"æ•°æ®é›†: {task['repo_id']}")
                print(f"çŠ¶æ€: {task['status']}")
                print(f"å·¥å…·: {task['tool']}")
                print(f"åˆ›å»ºæ—¶é—´: {task['created_at']}")
                if task.get('completed_at'):
                    print(f"å®Œæˆæ—¶é—´: {task['completed_at']}")
                if task.get('error_message'):
                    print(f"é”™è¯¯ä¿¡æ¯: {task['error_message']}")
            
        elif args.command == 'config':
            # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
            print(f"\n{Colors.BOLD}=== å½“å‰é…ç½®ä¿¡æ¯ ==={Colors.NC}")
            print(f"å…ƒæ•°æ®ç›®å½•: {config.get_metadata_dir()}")
            print(f"ä¸‹è½½ç›®å½•: {config.get_downloads_dir()}")
            print(f"æ—¥å¿—ç›®å½•: {config.get_logs_dir()}")
            print(f"HFç«¯ç‚¹: {config.get_hf_endpoint()}")
            
            proxies = config.get_proxies()
            if proxies:
                print(f"ä»£ç†è®¾ç½®:")
                for key, value in proxies.items():
                    print(f"  {key}: {value}")
            else:
                print(f"ä»£ç†è®¾ç½®: æœªè®¾ç½®")
            
            print(f"\n{Colors.BOLD}=== ç¯å¢ƒå˜é‡é…ç½® ==={Colors.NC}")
            env_vars = [
                ('METADATA_DIR', config.metadata_dir),
                ('DOWNLOADS_DIR', config.downloads_dir),
                ('LOGS_DIR', config.logs_dir),
                ('HF_ENDPOINT', config.hf_endpoint),
                ('HTTP_PROXY', config.http_proxy),
                ('HTTPS_PROXY', config.https_proxy),
                ('HF_TOKEN', '***å·²è®¾ç½®***' if os.getenv('HF_TOKEN') else 'æœªè®¾ç½®')
            ]
            
            for var_name, value in env_vars:
                if value:
                    print(f"{var_name}: {value}")
                else:
                    print(f"{var_name}: æœªè®¾ç½®")
            
        elif args.command == 'analyze-dataset':
            # åˆ†ææ•°æ®é›†å¤§å°å’Œç»“æ„
            print(f"{Colors.BLUE}æ­£åœ¨åˆ†ææ•°æ®é›† {args.repo_id}...{Colors.NC}")
            
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨å¿«é€Ÿæ¨¡å¼
            if args.quick:
                print(f"{Colors.YELLOW}ğŸš€ å¯ç”¨å¿«é€Ÿæ¨¡å¼ï¼ˆé‡‡æ · {args.sample_size} ä¸ªæ–‡ä»¶ï¼Œè¶…æ—¶ {args.timeout}sï¼‰{Colors.NC}")
            elif not args.quick:
                # è‡ªåŠ¨æ£€æµ‹æ˜¯å¦éœ€è¦å¿«é€Ÿæ¨¡å¼çš„æç¤º
                print(f"{Colors.CYAN}ğŸ’¡ æç¤ºï¼šå¦‚æœåˆ†æå¾ˆæ…¢ï¼Œå¯ä»¥ä½¿ç”¨ --quick å‚æ•°å¯ç”¨å¿«é€Ÿæ¨¡å¼{Colors.NC}")
            
            analysis = batch_manager.analyze_dataset_size(
                args.repo_id, 
                args.dataset,
                quick_mode=args.quick,
                sample_size=args.sample_size,
                timeout=args.timeout
            )
            
            if 'error' in analysis:
                print(f"{Colors.RED}âœ— åˆ†æå¤±è´¥: {analysis['error']}{Colors.NC}")
                return
            
            print(f"\n{Colors.BOLD}=== æ•°æ®é›†åˆ†æç»“æœ ==={Colors.NC}")
            print(f"åˆ†ææ¨¡å¼: {analysis.get('analysis_mode', 'unknown')}")
            print(f"åˆ†ææ—¶é—´: {analysis.get('analysis_time', 0):.1f}s")
            print(f"æ€»æ–‡ä»¶æ•°: {analysis['total_files']}")
            
            if analysis.get('is_estimated'):
                size_label = "é¢„ä¼°æ€»å¤§å°" if analysis.get('analysis_mode') == 'estimate' else "ä¼°ç®—æ€»å¤§å°"
                print(f"{size_label}: {analysis['total_size_formatted']} {Colors.YELLOW}ï¼ˆä¼°ç®—å€¼ï¼‰{Colors.NC}")
                if analysis.get('sample_files'):
                    print(f"é‡‡æ ·æ–‡ä»¶æ•°: {analysis.get('sample_files', 0)}")
                if analysis.get('estimation_note'):
                    print(f"ä¼°ç®—è¯´æ˜: {analysis['estimation_note']}")
            else:
                print(f"æ€»å¤§å°: {analysis['total_size_formatted']}")
            
            if analysis.get('file_types') and analysis.get('analysis_mode') != 'estimate':
                print(f"\n{Colors.BOLD}=== æ–‡ä»¶ç±»å‹åˆ†å¸ƒ ==={Colors.NC}")
                for ext, info in sorted(analysis['file_types'].items(), key=lambda x: x[1]['size'], reverse=True)[:10]:
                    if not ext or ext == 'no_extension':
                        ext = '<æ— æ‰©å±•å>'
                    print(f"{ext:<15} {info['count']:>6} ä¸ªæ–‡ä»¶ {format_file_size(info['size']):>12}")
            
            if analysis.get('largest_files'):
                print(f"\n{Colors.BOLD}=== æœ€å¤§çš„10ä¸ªæ–‡ä»¶ ==={Colors.NC}")
                for i, file_info in enumerate(analysis['largest_files'][:10], 1):
                    size = format_file_size(file_info.get('size', 0))
                    print(f"{i:>2}. {file_info['filename']:<50} {size:>12}")
            
            # ç»™å‡ºä¼˜åŒ–å»ºè®®
            analysis_mode = analysis.get('analysis_mode')
            if analysis_mode == 'estimate':
                print(f"\n{Colors.BOLD}=== é¢„ä¼°åˆ†æè¯´æ˜ ==={Colors.NC}")
                print(f"{Colors.CYAN}ğŸ” ç”±äºæ•°æ®é›†è¿‡å¤§ï¼Œæ— æ³•å¿«é€Ÿè·å–è¯¦ç»†æ–‡ä»¶åˆ—è¡¨{Colors.NC}")
                print(f"{Colors.CYAN}ğŸ“Š ä»¥ä¸Šä¸ºåŸºäºæ•°æ®é›†ç±»å‹çš„é¢„ä¼°å€¼ï¼Œå®é™…å¤§å°å¯èƒ½å·®å¼‚è¾ƒå¤§{Colors.NC}")
                print(f"{Colors.CYAN}ğŸ’¡ {analysis.get('recommendation', 'å»ºè®®ä½¿ç”¨åˆ†æ‰¹ä¸‹è½½åŠŸèƒ½')}{Colors.NC}")
                print(f"\n{Colors.BOLD}=== å»ºè®®æ“ä½œ ==={Colors.NC}")
                print(f"{Colors.YELLOW}ğŸš€ ç›´æ¥è¿›è¡Œåˆ†æ‰¹è§„åˆ’: python main.py plan-batch {args.repo_id} --available-space YOUR_SPACE {'--dataset' if args.dataset else ''}{Colors.NC}")
                print(f"{Colors.YELLOW}ğŸ“– æŸ¥çœ‹åˆ†æ‰¹ä¸‹è½½æŒ‡å—: å‚è€ƒ BATCH_DOWNLOAD_GUIDE.md{Colors.NC}")
            elif analysis_mode == 'quick':
                print(f"\n{Colors.BOLD}=== å¿«é€Ÿåˆ†æè¯´æ˜ ==={Colors.NC}")
                print(f"{Colors.CYAN}ğŸ“‹ è¿™æ˜¯åŸºäºé‡‡æ ·çš„å¿«é€Ÿåˆ†æç»“æœ{Colors.NC}")
                print(f"{Colors.CYAN}ğŸ“Š æ€»å¤§å°ä¸ºä¼°ç®—å€¼ï¼ˆåŸºäº {analysis.get('sample_files', 0)} ä¸ªæ–‡ä»¶çš„å¹³å‡å¤§å°ï¼‰{Colors.NC}")
                print(f"{Colors.CYAN}ğŸ’¡ å¦‚éœ€ç²¾ç¡®åˆ†æï¼Œè¯·å»æ‰ --quick å‚æ•°é‡æ–°æ‰§è¡Œ{Colors.NC}")
            elif analysis.get('total_files', 0) > 1000:
                print(f"\n{Colors.BOLD}=== æ€§èƒ½å»ºè®® ==={Colors.NC}")
                print(f"{Colors.YELLOW}ğŸ“ˆ æ£€æµ‹åˆ°å¤§å‹æ•°æ®é›†ï¼ˆ{analysis['total_files']} ä¸ªæ–‡ä»¶ï¼‰{Colors.NC}")
                print(f"{Colors.YELLOW}ğŸš€ ä¸‹æ¬¡å¯ä½¿ç”¨ --quick å‚æ•°è¿›è¡Œå¿«é€Ÿåˆ†æ{Colors.NC}")
                print(f"{Colors.YELLOW}â±ï¸  å‘½ä»¤ç¤ºä¾‹: python main.py analyze-dataset {args.repo_id} --quick {'--dataset' if args.dataset else ''}{Colors.NC}")
                
        elif args.command == 'plan-batch':
            # è§„åˆ’åˆ†æ‰¹ä¸‹è½½ç­–ç•¥
            print(f"{Colors.BLUE}æ­£åœ¨è§„åˆ’åˆ†æ‰¹ä¸‹è½½ç­–ç•¥...{Colors.NC}")
            
            plan = batch_manager.plan_batch_download(
                args.repo_id, 
                args.available_space,
                args.dataset,
                args.safety_margin
            )
            
            if 'error' in plan:
                print(f"{Colors.RED}âœ— è§„åˆ’å¤±è´¥: {plan['error']}{Colors.NC}")
                return
            
            # æ˜¾ç¤ºç®¡ç†ç­–ç•¥å»ºè®®
            strategy = batch_manager.suggest_disk_management_strategy(plan, args.available_space)
            
            if strategy['strategy'] != 'no_management_needed':
                print(f"\n{Colors.BOLD}=== ç£ç›˜ç®¡ç†å»ºè®® ==={Colors.NC}")
                
                for suggestion in strategy['suggestions']:
                    if suggestion['type'] == 'warning':
                        print(f"{Colors.RED}âš  {suggestion['message']}{Colors.NC}")
                    elif suggestion['type'] == 'recommendation':
                        print(f"{Colors.YELLOW}ğŸ’¡ {suggestion['message']}{Colors.NC}")
                    elif suggestion['type'] == 'info':
                        print(f"{Colors.CYAN}â„¹ {suggestion['message']}{Colors.NC}")
                
                print(f"\n{Colors.BOLD}=== ç£ç›˜ä½¿ç”¨æ—¶é—´çº¿ ==={Colors.NC}")
                timeline = strategy['timeline']
                for entry in timeline:
                    print(f"æ‰¹æ¬¡ {entry['batch']:>2}: {entry['files_count']:>4} æ–‡ä»¶, "
                          f"å½“å‰æ‰¹æ¬¡ {entry['batch_size_formatted']:>8}, "
                          f"ç´¯è®¡ {entry['cumulative_size_formatted']:>8}")
                
                print(f"\né¢„è®¡å³°å€¼ç£ç›˜ä½¿ç”¨: {strategy['estimated_peak_usage']}")
            
            # ä¿å­˜è§„åˆ’ç»“æœä¾›åç»­ä½¿ç”¨
            plan_file = config.get_metadata_dir() / f"batch_plan_{args.repo_id.replace('/', '_')}.json"
            from utils import save_json_file
            save_json_file(plan_file, plan)
            print(f"\n{Colors.GREEN}âœ“ åˆ†æ‰¹è§„åˆ’å·²ä¿å­˜åˆ°: {plan_file}{Colors.NC}")
                
        elif args.command == 'batch-download':
            # æ‰§è¡Œåˆ†æ‰¹ä¸‹è½½
            print(f"{Colors.BLUE}å¼€å§‹æ‰§è¡Œåˆ†æ‰¹ä¸‹è½½...{Colors.NC}")
            
            # é¦–å…ˆè§„åˆ’ä¸‹è½½ç­–ç•¥
            plan = batch_manager.plan_batch_download(
                args.repo_id,
                args.available_space, 
                args.dataset
            )
            
            if 'error' in plan:
                print(f"{Colors.RED}âœ— è§„åˆ’å¤±è´¥: {plan['error']}{Colors.NC}")
                return
            
            # åˆ›å»ºä¸‹è½½ä»»åŠ¡
            if not dataset_manager.get_dataset(args.repo_id):
                print(f"{Colors.YELLOW}æ•°æ®é›† '{args.repo_id}' ä¸å­˜åœ¨ï¼Œè‡ªåŠ¨æ·»åŠ ...{Colors.NC}")
                dataset_manager.add_dataset(args.repo_id, is_dataset=args.dataset)
            
            task_id = task_manager.create_task(
                repo_id=args.repo_id,
                is_dataset=args.dataset
            )
            
            print(f"{Colors.GREEN}âœ“ ä¸‹è½½ä»»åŠ¡å·²åˆ›å»ºï¼Œä»»åŠ¡ID: {task_id}{Colors.NC}")
            
            # æ‰§è¡Œåˆ†æ‰¹ä¸‹è½½
            success = batch_manager.execute_batch_download(
                task_id, plan, current_batch=1, auto_proceed=args.auto_proceed
            )
            
            if success:
                print(f"{Colors.GREEN}âœ“ åˆ†æ‰¹ä¸‹è½½æ‰§è¡Œå®Œæˆ{Colors.NC}")
            else:
                print(f"{Colors.RED}âœ— åˆ†æ‰¹ä¸‹è½½æ‰§è¡Œå¤±è´¥{Colors.NC}")
                
        elif args.command == 'batch-continue':
            # ç»§ç»­åˆ†æ‰¹ä¸‹è½½
            print(f"{Colors.BLUE}ç»§ç»­åˆ†æ‰¹ä¸‹è½½ï¼Œä»»åŠ¡ID: {args.task_id}, æ‰¹æ¬¡: {args.batch_number}{Colors.NC}")
            
            # è·å–æ‰¹æ¬¡è¿›åº¦
            progress = batch_manager.get_batch_progress(args.task_id)
            if not progress:
                print(f"{Colors.RED}âœ— æœªæ‰¾åˆ°ä»»åŠ¡ {args.task_id} çš„æ‰¹æ¬¡ä¿¡æ¯{Colors.NC}")
                return
            
            # åŠ è½½åŸæœ‰çš„è§„åˆ’
            task = task_manager.get_task(args.task_id)
            if not task:
                print(f"{Colors.RED}âœ— ä»»åŠ¡ {args.task_id} ä¸å­˜åœ¨{Colors.NC}")
                return
            
            plan_file = config.get_metadata_dir() / f"batch_plan_{task['repo_id'].replace('/', '_')}.json"
            
            if not plan_file.exists():
                print(f"{Colors.RED}âœ— æœªæ‰¾åˆ°æ‰¹æ¬¡è§„åˆ’æ–‡ä»¶{Colors.NC}")
                return
            
            from utils import load_json_file
            plan = load_json_file(plan_file)
            
            # ç»§ç»­æ‰§è¡Œä¸‹è½½
            success = batch_manager.execute_batch_download(
                args.task_id, plan, current_batch=args.batch_number, auto_proceed=False
            )
            
            if success:
                print(f"{Colors.GREEN}âœ“ æ‰¹æ¬¡ç»§ç»­æ‰§è¡Œå®Œæˆ{Colors.NC}")
            else:
                print(f"{Colors.RED}âœ— æ‰¹æ¬¡ç»§ç»­æ‰§è¡Œå¤±è´¥{Colors.NC}")
                
        elif args.command == 'batch-status':
            # æŸ¥çœ‹åˆ†æ‰¹ä¸‹è½½çŠ¶æ€
            print(f"{Colors.BLUE}æŸ¥çœ‹åˆ†æ‰¹ä¸‹è½½çŠ¶æ€ï¼Œä»»åŠ¡ID: {args.task_id}{Colors.NC}")
            
            progress = batch_manager.get_batch_progress(args.task_id)
            if not progress:
                print(f"{Colors.RED}âœ— æœªæ‰¾åˆ°ä»»åŠ¡ {args.task_id} çš„æ‰¹æ¬¡ä¿¡æ¯{Colors.NC}")
                return
                
            task = task_manager.get_task(args.task_id)
            if not task:
                print(f"{Colors.RED}âœ— ä»»åŠ¡ {args.task_id} ä¸å­˜åœ¨{Colors.NC}")
                return
            
            print(f"\n{Colors.BOLD}=== åˆ†æ‰¹ä¸‹è½½çŠ¶æ€ ==={Colors.NC}")
            print(f"ä»»åŠ¡ID: {progress['task_id']}")
            print(f"æ•°æ®é›†: {task['repo_id']}")
            print(f"å½“å‰æ‰¹æ¬¡: {progress['current_batch']}/{progress['total_batches']}")
            print(f"å½“å‰æ‰¹æ¬¡å¤§å°: {format_file_size(progress['batch_size'])}")
            print(f"æœ€åæ›´æ–°: {progress['timestamp']}")
            
            completion_rate = (progress['current_batch'] - 1) / progress['total_batches'] * 100
            print(f"æ€»ä½“è¿›åº¦: {completion_rate:.1f}%")
            
            if progress['current_batch'] <= progress['total_batches']:
                remaining_batches = progress['total_batches'] - progress['current_batch'] + 1
                print(f"å‰©ä½™æ‰¹æ¬¡: {remaining_batches}")
                
        elif args.command == 'delete-task':
            handle_delete_task(args)
            
        elif args.command == 'cleanup':
            handle_cleanup(args)
    
    except KeyboardInterrupt:
        print(f"\n{Colors.YELLOW}æ“ä½œè¢«ç”¨æˆ·ä¸­æ–­{Colors.NC}")
        sys.exit(1)
    except Exception as e:
        print(f"{Colors.RED}âœ— é”™è¯¯: {str(e)}{Colors.NC}")
        sys.exit(1)

if __name__ == '__main__':
    main() 