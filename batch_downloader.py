"""
åˆ†æ‰¹ä¸‹è½½ç®¡ç†å™¨
ä¸“é—¨å¤„ç†å¤§æ•°æ®é›†çš„åˆ†æ‰¹ä¸‹è½½ï¼Œæ”¯æŒå­˜å‚¨ç©ºé—´é™åˆ¶å’Œæ¢ç›˜åœºæ™¯
"""

import os
import shutil
import time
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from datetime import datetime

from config import get_config
from utils import Colors, format_file_size, get_current_timestamp
from file_tracker import FileTracker
from system_monitor import SystemMonitor
from downloader import DownloadManager

class BatchDownloadManager:
    """åˆ†æ‰¹ä¸‹è½½ç®¡ç†å™¨"""
    
    def __init__(self):
        self.config = get_config()
        self.system_monitor = SystemMonitor()
        self.download_manager = DownloadManager()
        
    def analyze_dataset_size(self, repo_id: str, is_dataset: bool = False, 
                           quick_mode: bool = False, 
                           sample_size: int = 100,
                           timeout: int = 30) -> Dict:
        """åˆ†ææ•°æ®é›†å¤§å°å’Œæ–‡ä»¶åˆ†å¸ƒ
        
        Args:
            repo_id: ä»“åº“ID
            is_dataset: æ˜¯å¦ä¸ºæ•°æ®é›†
            quick_mode: å¿«é€Ÿæ¨¡å¼ï¼Œä»…é‡‡æ ·åˆ†æ
            sample_size: é‡‡æ ·æ–‡ä»¶æ•°é‡
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        """
        print(f"{Colors.YELLOW}æ­£åœ¨åˆ†ææ•°æ®é›† {repo_id}...{Colors.NC}")
        
        start_time = time.time()
        
        # è·å–æ–‡ä»¶åˆ—è¡¨ï¼ˆå¸¦è¶…æ—¶ï¼‰
        try:
            print(f"{Colors.BLUE}ğŸ“¡ è·å–æ–‡ä»¶åˆ—è¡¨...{Colors.NC}")
            file_list = self._get_file_list_with_timeout(repo_id, is_dataset, timeout)
            
            if not file_list:
                print(f"{Colors.YELLOW}âš ï¸  æ— æ³•è·å–æ–‡ä»¶åˆ—è¡¨ï¼Œå°è¯•é¢„ä¼°åˆ†æ...{Colors.NC}")
                return self._estimate_analysis(repo_id, is_dataset, start_time)
            
            total_files = len(file_list)
            print(f"{Colors.GREEN}âœ“ æ‰¾åˆ° {total_files} ä¸ªæ–‡ä»¶{Colors.NC}")
            
            # å¦‚æœæ–‡ä»¶æ•°é‡å¾ˆå¤§ä¸”å¯ç”¨å¿«é€Ÿæ¨¡å¼ï¼Œä½¿ç”¨é‡‡æ ·åˆ†æ
            if quick_mode or total_files > 1000:
                print(f"{Colors.YELLOW}ğŸ”„ æ•°æ®é›†è¾ƒå¤§ï¼Œä½¿ç”¨å¿«é€Ÿé‡‡æ ·åˆ†æï¼ˆé‡‡æ · {min(sample_size, total_files)} ä¸ªæ–‡ä»¶ï¼‰{Colors.NC}")
                return self._quick_analyze(file_list, sample_size, start_time)
            else:
                print(f"{Colors.BLUE}ğŸ“Š æ‰§è¡Œå®Œæ•´åˆ†æ...{Colors.NC}")
                return self._full_analyze(file_list, start_time)
                
        except Exception as e:
            elapsed = time.time() - start_time
            print(f"{Colors.RED}âœ— åˆ†æå¤±è´¥ ({elapsed:.1f}s): {str(e)}{Colors.NC}")
            print(f"{Colors.YELLOW}ğŸ”„ å°è¯•é¢„ä¼°åˆ†æ...{Colors.NC}")
            return self._estimate_analysis(repo_id, is_dataset, start_time)
    
    def _get_file_list_with_timeout(self, repo_id: str, is_dataset: bool, timeout: int) -> List[Dict]:
        """å¸¦è¶…æ—¶çš„æ–‡ä»¶åˆ—è¡¨è·å–"""
        result = [None]
        error = [None]
        
        def get_files():
            try:
                result[0] = self.download_manager._get_file_list(repo_id, is_dataset)
            except Exception as e:
                error[0] = e
        
        # åˆ›å»ºçº¿ç¨‹æ‰§è¡Œè·å–æ–‡ä»¶åˆ—è¡¨
        thread = threading.Thread(target=get_files)
        thread.daemon = True
        thread.start()
        thread.join(timeout)
        
        if thread.is_alive():
            print(f"{Colors.RED}âš ï¸  è·å–æ–‡ä»¶åˆ—è¡¨è¶…æ—¶ ({timeout}s)ï¼Œå»ºè®®ä½¿ç”¨å¿«é€Ÿæ¨¡å¼{Colors.NC}")
            return []
        
        if error[0]:
            raise error[0]
            
        return result[0] or []
    
    def _quick_analyze(self, file_list: List[Dict], sample_size: int, start_time: float) -> Dict:
        """å¿«é€Ÿé‡‡æ ·åˆ†æ"""
        total_files = len(file_list)
        
        # æ™ºèƒ½é‡‡æ ·ï¼šåŒ…å«æœ€å¤§æ–‡ä»¶å’Œéšæœºé‡‡æ ·
        sorted_by_size = sorted(file_list, key=lambda x: x.get('size', 0), reverse=True)
        
        # å–å‰50%çš„å¤§æ–‡ä»¶ + éšæœºé‡‡æ ·
        large_files_count = min(sample_size // 2, len(sorted_by_size))
        large_files = sorted_by_size[:large_files_count]
        
        # ä»å‰©ä½™æ–‡ä»¶ä¸­éšæœºé‡‡æ ·
        remaining_files = sorted_by_size[large_files_count:]
        import random
        random_sample_count = min(sample_size - large_files_count, len(remaining_files))
        random_files = random.sample(remaining_files, random_sample_count) if remaining_files else []
        
        sample_files = large_files + random_files
        
        # è®¡ç®—é‡‡æ ·ç»Ÿè®¡
        sample_total_size = sum(f.get('size', 0) for f in sample_files)
        sample_avg_size = sample_total_size / len(sample_files) if sample_files else 0
        
        # ä¼°ç®—æ€»å¤§å°
        estimated_total_size = int(sample_avg_size * total_files)
        
        # åˆ†ææ–‡ä»¶ç±»å‹ï¼ˆåŸºäºé‡‡æ ·ï¼‰
        file_types = self._analyze_file_types(sample_files)
        
        elapsed = time.time() - start_time
        
        print(f"{Colors.GREEN}âœ“ å¿«é€Ÿåˆ†æå®Œæˆ ({elapsed:.1f}s){Colors.NC}")
        print(f"  ğŸ“ æ€»æ–‡ä»¶æ•°: {total_files}")
        print(f"  ğŸ“Š é‡‡æ ·æ–‡ä»¶: {len(sample_files)}")
        print(f"  ğŸ“ ä¼°ç®—æ€»å¤§å°: {format_file_size(estimated_total_size)}")
        
        return {
            'analysis_mode': 'quick',
            'analysis_time': elapsed,
            'total_files': total_files,
            'sample_files': len(sample_files),
            'sample_size': sample_total_size,
            'estimated_total_size': estimated_total_size,
            'total_size_formatted': format_file_size(estimated_total_size),
            'largest_files': sorted_by_size[:10],
            'file_types': file_types,
            'file_list': file_list,  # å®Œæ•´åˆ—è¡¨ç”¨äºåç»­è§„åˆ’
            'is_estimated': True
        }
    
    def _full_analyze(self, file_list: List[Dict], start_time: float) -> Dict:
        """å®Œæ•´åˆ†æ"""
        print(f"{Colors.BLUE}ğŸ“Š åˆ†ææ–‡ä»¶å¤§å°å’Œç±»å‹...{Colors.NC}")
        
        # å¹¶å‘è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        with ThreadPoolExecutor(max_workers=4) as executor:
            # æäº¤ä»»åŠ¡
            futures = {
                'total_size': executor.submit(self._calculate_total_size, file_list),
                'file_types': executor.submit(self._analyze_file_types, file_list),
                'sorted_files': executor.submit(self._sort_files_by_size, file_list)
            }
            
            # è·å–ç»“æœ
            results = {}
            for key, future in futures.items():
                try:
                    results[key] = future.result(timeout=15)  # 15ç§’è¶…æ—¶
                except Exception as e:
                    print(f"{Colors.RED}âš ï¸  {key} è®¡ç®—å¤±è´¥: {e}{Colors.NC}")
                    results[key] = None
        
        total_size = results.get('total_size', 0)
        file_types = results.get('file_types', {})
        sorted_files = results.get('sorted_files', [])
        
        elapsed = time.time() - start_time
        
        print(f"{Colors.GREEN}âœ“ å®Œæ•´åˆ†æå®Œæˆ ({elapsed:.1f}s){Colors.NC}")
        print(f"  ğŸ“ æ€»æ–‡ä»¶æ•°: {len(file_list)}")
        print(f"  ğŸ“ æ€»å¤§å°: {format_file_size(total_size)}")
        
        return {
            'analysis_mode': 'full',
            'analysis_time': elapsed,
            'total_files': len(file_list),
            'total_size': total_size,
            'total_size_formatted': format_file_size(total_size),
            'largest_files': sorted_files[:10],
            'file_types': file_types,
            'file_list': file_list,
            'is_estimated': False
        }
    
    def _calculate_total_size(self, file_list: List[Dict]) -> int:
        """è®¡ç®—æ€»å¤§å°"""
        return sum(f.get('size', 0) for f in file_list)
    
    def _analyze_file_types(self, file_list: List[Dict]) -> Dict:
        """åˆ†ææ–‡ä»¶ç±»å‹åˆ†å¸ƒ"""
        file_types = {}
        for file_info in file_list:
            ext = Path(file_info['filename']).suffix.lower()
            if not ext:
                ext = 'no_extension'
            if ext not in file_types:
                file_types[ext] = {'count': 0, 'size': 0}
            file_types[ext]['count'] += 1
            file_types[ext]['size'] += file_info.get('size', 0)
        return file_types
    
    def _sort_files_by_size(self, file_list: List[Dict]) -> List[Dict]:
        """æŒ‰å¤§å°æ’åºæ–‡ä»¶"""
        return sorted(file_list, key=lambda x: x.get('size', 0), reverse=True)
    
    def _estimate_analysis(self, repo_id: str, is_dataset: bool, start_time: float) -> Dict:
        """é¢„ä¼°åˆ†ææ¨¡å¼ - å½“æ— æ³•è·å–è¯¦ç»†æ–‡ä»¶åˆ—è¡¨æ—¶çš„fallback"""
        elapsed = time.time() - start_time
        
        print(f"{Colors.CYAN}ğŸ” ä½¿ç”¨é¢„ä¼°åˆ†ææ¨¡å¼...{Colors.NC}")
        
        # åŸºäºæ•°æ®é›†ç±»å‹çš„ç»éªŒä¼°ç®—
        if is_dataset:
            # æ•°æ®é›†é€šå¸¸è¾ƒå¤§
            estimated_files = 1000  # é¢„ä¼°æ–‡ä»¶æ•°
            estimated_avg_size = 50 * 1024 * 1024  # 50MBå¹³å‡å¤§å°
            note = "å¤§å‹æ•°æ®é›†ï¼ˆç»éªŒä¼°ç®—ï¼‰"
        else:
            # æ¨¡å‹é€šå¸¸ç›¸å¯¹è¾ƒå°
            estimated_files = 100  # é¢„ä¼°æ–‡ä»¶æ•°
            estimated_avg_size = 10 * 1024 * 1024  # 10MBå¹³å‡å¤§å°
            note = "æ¨¡å‹æ–‡ä»¶ï¼ˆç»éªŒä¼°ç®—ï¼‰"
        
        estimated_total_size = estimated_files * estimated_avg_size
        
        print(f"{Colors.YELLOW}âš ï¸  é¢„ä¼°åˆ†æå®Œæˆ ({elapsed:.1f}s){Colors.NC}")
        print(f"  ğŸ“ é¢„ä¼°æ–‡ä»¶æ•°: {estimated_files}")
        print(f"  ğŸ“ é¢„ä¼°æ€»å¤§å°: {format_file_size(estimated_total_size)}")
        print(f"  ğŸ“ è¯´æ˜: {note}")
        
        return {
            'analysis_mode': 'estimate',
            'analysis_time': elapsed,
            'total_files': estimated_files,
            'estimated_total_size': estimated_total_size,
            'total_size': estimated_total_size,  # å‘åå…¼å®¹
            'total_size_formatted': format_file_size(estimated_total_size),
            'largest_files': [],
            'file_types': {'unknown': {'count': estimated_files, 'size': estimated_total_size}},
            'file_list': [],  # ç©ºåˆ—è¡¨ï¼Œåç»­éœ€è¦å®é™…ä¸‹è½½æ—¶å†è·å–
            'is_estimated': True,
            'estimation_note': note,
            'recommendation': f"å¯¹äºæ­¤è¶…å¤§æ•°æ®é›†ï¼Œå»ºè®®å…ˆä½¿ç”¨ plan-batch å‘½ä»¤è¿›è¡Œåˆ†æ‰¹è§„åˆ’"
        }
    
    def plan_batch_download(self, repo_id: str, available_space: int, 
                          is_dataset: bool = False, 
                          safety_margin: float = 0.9) -> Dict:
        """è§„åˆ’åˆ†æ‰¹ä¸‹è½½ç­–ç•¥"""
        
        analysis = self.analyze_dataset_size(repo_id, is_dataset)
        if 'error' in analysis:
            return analysis
        
        file_list = analysis['file_list']
        total_size = analysis['total_size']
        
        # è®¡ç®—å®‰å…¨å¯ç”¨ç©ºé—´ï¼ˆç•™å‡º10%å®‰å…¨ä½™é‡ï¼‰
        safe_space = int(available_space * safety_margin)
        
        print(f"\n{Colors.BOLD}=== åˆ†æ‰¹ä¸‹è½½è§„åˆ’ ==={Colors.NC}")
        print(f"æ•°æ®é›†æ€»å¤§å°: {format_file_size(total_size)}")
        print(f"å¯ç”¨ç©ºé—´: {format_file_size(available_space)}")
        print(f"å®‰å…¨å¯ç”¨ç©ºé—´: {format_file_size(safe_space)} (é¢„ç•™{int((1-safety_margin)*100)}%å®‰å…¨ä½™é‡)")
        
        if total_size <= safe_space:
            print(f"{Colors.GREEN}âœ“ ç©ºé—´å……è¶³ï¼Œå¯ä»¥ä¸€æ¬¡æ€§ä¸‹è½½{Colors.NC}")
            return {
                'strategy': 'single_batch',
                'batches': [{'files': file_list, 'size': total_size}],
                'total_batches': 1
            }
        
        # éœ€è¦åˆ†æ‰¹ä¸‹è½½
        batches = self._create_batches(file_list, safe_space)
        
        print(f"{Colors.YELLOW}éœ€è¦åˆ† {len(batches)} æ‰¹æ¬¡ä¸‹è½½{Colors.NC}")
        for i, batch in enumerate(batches, 1):
            print(f"  æ‰¹æ¬¡ {i}: {len(batch['files'])} ä¸ªæ–‡ä»¶, {format_file_size(batch['size'])}")
        
        return {
            'strategy': 'multi_batch',
            'batches': batches,
            'total_batches': len(batches),
            'available_space': available_space,
            'safe_space': safe_space
        }
    
    def _create_batches(self, file_list: List[Dict], max_batch_size: int) -> List[Dict]:
        """åˆ›å»ºä¸‹è½½æ‰¹æ¬¡"""
        batches = []
        current_batch = {'files': [], 'size': 0}
        
        # æŒ‰æ–‡ä»¶å¤§å°æ’åºï¼Œä¼˜å…ˆä¸‹è½½å¤§æ–‡ä»¶
        sorted_files = sorted(file_list, key=lambda x: x.get('size', 0), reverse=True)
        
        for file_info in sorted_files:
            file_size = file_info.get('size', 0)
            
            # å¦‚æœå•ä¸ªæ–‡ä»¶å°±è¶…è¿‡æ‰¹æ¬¡é™åˆ¶
            if file_size > max_batch_size:
                # å•ç‹¬æˆä¸ºä¸€ä¸ªæ‰¹æ¬¡
                if current_batch['files']:
                    batches.append(current_batch)
                    current_batch = {'files': [], 'size': 0}
                
                batches.append({
                    'files': [file_info],
                    'size': file_size,
                    'note': 'è¶…å¤§æ–‡ä»¶å•ç‹¬æ‰¹æ¬¡'
                })
                continue
            
            # æ£€æŸ¥æ˜¯å¦èƒ½æ”¾å…¥å½“å‰æ‰¹æ¬¡
            if current_batch['size'] + file_size <= max_batch_size:
                current_batch['files'].append(file_info)
                current_batch['size'] += file_size
            else:
                # å½“å‰æ‰¹æ¬¡å·²æ»¡ï¼Œå¼€å§‹æ–°æ‰¹æ¬¡
                if current_batch['files']:
                    batches.append(current_batch)
                current_batch = {'files': [file_info], 'size': file_size}
        
        # æ·»åŠ æœ€åä¸€ä¸ªæ‰¹æ¬¡
        if current_batch['files']:
            batches.append(current_batch)
        
        return batches
    
    def execute_batch_download(self, task_id: str, plan: Dict, 
                             current_batch: int = 1, 
                             auto_proceed: bool = False) -> bool:
        """æ‰§è¡Œåˆ†æ‰¹ä¸‹è½½"""
        
        if plan['strategy'] == 'single_batch':
            print(f"{Colors.GREEN}æ‰§è¡Œå•æ‰¹æ¬¡ä¸‹è½½...{Colors.NC}")
            return self.download_manager.start_download(task_id)
        
        # å¤šæ‰¹æ¬¡ä¸‹è½½
        total_batches = plan['total_batches']
        
        if current_batch > total_batches:
            print(f"{Colors.GREEN}âœ“ æ‰€æœ‰æ‰¹æ¬¡å·²ä¸‹è½½å®Œæˆ{Colors.NC}")
            return True
        
        print(f"\n{Colors.BOLD}=== æ‰§è¡Œæ‰¹æ¬¡ {current_batch}/{total_batches} ==={Colors.NC}")
        
        batch = plan['batches'][current_batch - 1]
        batch_files = batch['files']
        batch_size = batch['size']
        
        print(f"æ‰¹æ¬¡ä¿¡æ¯: {len(batch_files)} ä¸ªæ–‡ä»¶, {format_file_size(batch_size)}")
        
        # æ£€æŸ¥å½“å‰å¯ç”¨ç©ºé—´
        task_manager = self.download_manager.task_manager
        task = task_manager.get_task(task_id)
        download_path = self.download_manager._prepare_download_directory(
            task_id, task['repo_id'], task.get('local_dir')
        )
        
        system_check = self.system_monitor.comprehensive_check(download_path, batch_size)
        
        if system_check['disk_space']['status'] in ['critical', 'error']:
            print(f"{Colors.RED}âœ— ç£ç›˜ç©ºé—´ä¸è¶³ï¼Œæ— æ³•ç»§ç»­ä¸‹è½½æ­¤æ‰¹æ¬¡{Colors.NC}")
            print(f"éœ€è¦è‡³å°‘ {format_file_size(batch_size)} ç©ºé—´")
            return False
        
        # åˆ›å»ºå½“å‰æ‰¹æ¬¡çš„æ–‡ä»¶è·Ÿè¸ªå™¨
        file_tracker = FileTracker(f"{task_id}_batch_{current_batch}")
        file_tracker.initialize_file_list(batch_files)
        
        # ä¿å­˜æ‰¹æ¬¡ä¿¡æ¯åˆ°ä»»åŠ¡å…ƒæ•°æ®
        self._save_batch_progress(task_id, current_batch, total_batches, batch_size)
        
        # æ‰§è¡Œå½“å‰æ‰¹æ¬¡ä¸‹è½½
        print(f"{Colors.BLUE}å¼€å§‹ä¸‹è½½æ‰¹æ¬¡ {current_batch}...{Colors.NC}")
        
        success = self._download_batch(task_id, task, batch_files, download_path, file_tracker)
        
        if success:
            print(f"{Colors.GREEN}âœ“ æ‰¹æ¬¡ {current_batch} ä¸‹è½½å®Œæˆ{Colors.NC}")
            
            if current_batch < total_batches:
                print(f"\n{Colors.YELLOW}=== å‡†å¤‡ä¸‹ä¸€æ‰¹æ¬¡ ==={Colors.NC}")
                print(f"æ‰¹æ¬¡ {current_batch} å·²å®Œæˆï¼Œè¿˜æœ‰ {total_batches - current_batch} ä¸ªæ‰¹æ¬¡")
                
                if not auto_proceed:
                    print(f"{Colors.CYAN}è¯·å®Œæˆä»¥ä¸‹æ“ä½œåç»§ç»­:{Colors.NC}")
                    print(f"1. å¤‡ä»½/ç§»åŠ¨å½“å‰ä¸‹è½½çš„æ–‡ä»¶ï¼ˆå¦‚éœ€è¦ï¼‰")
                    print(f"2. æ¸…ç†ç£ç›˜ç©ºé—´ä¸ºä¸‹ä¸€æ‰¹æ¬¡è…¾å‡ºç©ºé—´")
                    print(f"3. è¿è¡Œ: python main.py batch-continue {task_id} {current_batch + 1}")
                    return True
                else:
                    # è‡ªåŠ¨ç»§ç»­ä¸‹ä¸€æ‰¹æ¬¡
                    return self.execute_batch_download(task_id, plan, current_batch + 1, auto_proceed)
            else:
                print(f"{Colors.GREEN}ğŸ‰ æ‰€æœ‰æ‰¹æ¬¡ä¸‹è½½å®Œæˆï¼{Colors.NC}")
                return True
        else:
            print(f"{Colors.RED}âœ— æ‰¹æ¬¡ {current_batch} ä¸‹è½½å¤±è´¥{Colors.NC}")
            return False
    
    def _download_batch(self, task_id: str, task: Dict, file_list: List[Dict], 
                       download_path: Path, file_tracker: FileTracker) -> bool:
        """ä¸‹è½½å•ä¸ªæ‰¹æ¬¡"""
        
        if task['tool'] == 'aria2c':
            return self.download_manager._download_with_aria2c(
                task_id, task, file_list, download_path, file_tracker
            )
        else:
            return self.download_manager._download_with_wget(
                task_id, task, file_list, download_path, file_tracker
            )
    
    def _save_batch_progress(self, task_id: str, current_batch: int, 
                           total_batches: int, batch_size: int):
        """ä¿å­˜æ‰¹æ¬¡è¿›åº¦ä¿¡æ¯"""
        batch_metadata = {
            'task_id': task_id,
            'current_batch': current_batch,
            'total_batches': total_batches,
            'batch_size': batch_size,
            'timestamp': get_current_timestamp()
        }
        
        metadata_dir = self.config.get_metadata_dir() / 'tasks' / task_id
        metadata_dir.mkdir(parents=True, exist_ok=True)
        
        batch_file = metadata_dir / 'batch_progress.json'
        
        from utils import save_json_file
        save_json_file(batch_file, batch_metadata)
    
    def get_batch_progress(self, task_id: str) -> Optional[Dict]:
        """è·å–æ‰¹æ¬¡è¿›åº¦ä¿¡æ¯"""
        metadata_dir = self.config.get_metadata_dir() / 'tasks' / task_id
        batch_file = metadata_dir / 'batch_progress.json'
        
        if batch_file.exists():
            from utils import load_json_file
            return load_json_file(batch_file)
        
        return None
    
    def estimate_disk_usage_over_time(self, plan: Dict) -> List[Dict]:
        """ä¼°ç®—åˆ†æ‰¹ä¸‹è½½çš„ç£ç›˜ä½¿ç”¨æƒ…å†µ"""
        usage_timeline = []
        cumulative_size = 0
        
        for i, batch in enumerate(plan['batches'], 1):
            cumulative_size += batch['size']
            usage_timeline.append({
                'batch': i,
                'batch_size': batch['size'],
                'cumulative_size': cumulative_size,
                'files_count': len(batch['files']),
                'batch_size_formatted': format_file_size(batch['size']),
                'cumulative_size_formatted': format_file_size(cumulative_size)
            })
        
        return usage_timeline
    
    def suggest_disk_management_strategy(self, plan: Dict, available_space: int) -> Dict:
        """å»ºè®®ç£ç›˜ç®¡ç†ç­–ç•¥"""
        
        if plan['strategy'] == 'single_batch':
            return {'strategy': 'no_management_needed'}
        
        timeline = self.estimate_disk_usage_over_time(plan)
        max_batch_size = max(batch['size'] for batch in plan['batches'])
        
        suggestions = []
        
        # å¦‚æœæœ€å¤§æ‰¹æ¬¡æ¥è¿‘å¯ç”¨ç©ºé—´
        if max_batch_size > available_space * 0.8:
            suggestions.append({
                'type': 'warning',
                'message': f"æœ€å¤§æ‰¹æ¬¡å¤§å° {format_file_size(max_batch_size)} æ¥è¿‘å¯ç”¨ç©ºé—´é™åˆ¶"
            })
        
        # å»ºè®®ä¸­é—´æ¸…ç†ç­–ç•¥
        if len(plan['batches']) > 2:
            suggestions.append({
                'type': 'recommendation', 
                'message': "å»ºè®®æ¯å®Œæˆ2-3ä¸ªæ‰¹æ¬¡åè¿›è¡Œä¸€æ¬¡æ–‡ä»¶å¤‡ä»½å’Œæ¸…ç†"
            })
        
        # å¦‚æœæœ‰è¶…å¤§æ–‡ä»¶
        large_batches = [b for b in plan['batches'] if b.get('note') == 'è¶…å¤§æ–‡ä»¶å•ç‹¬æ‰¹æ¬¡']
        if large_batches:
            suggestions.append({
                'type': 'info',
                'message': f"æ£€æµ‹åˆ° {len(large_batches)} ä¸ªè¶…å¤§æ–‡ä»¶éœ€è¦å•ç‹¬å¤„ç†"
            })
        
        return {
            'strategy': 'batch_management',
            'timeline': timeline,
            'suggestions': suggestions,
            'estimated_peak_usage': format_file_size(max_batch_size),
            'total_batches': len(plan['batches'])
        } 