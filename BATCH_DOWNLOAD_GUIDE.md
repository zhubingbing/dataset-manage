# ğŸš€ åˆ†æ‰¹ä¸‹è½½åŠŸèƒ½å®Œå…¨æŒ‡å—

## ğŸ¯ è§£å†³çš„é—®é¢˜

å¯¹äºæ‚¨æåˆ°çš„åœºæ™¯ï¼ˆ30TBæ•°æ®é›† vs 10TBå­˜å‚¨ç©ºé—´ï¼‰ï¼Œæˆ‘ä»¬çš„åˆ†æ‰¹ä¸‹è½½ç®¡ç†å™¨å®Œå…¨è§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼š

- âœ… **æ™ºèƒ½åˆ†æ‰¹è§„åˆ’** - æ ¹æ®å¯ç”¨ç©ºé—´è‡ªåŠ¨åˆ†æ‰¹
- âœ… **æ¢ç›˜æ— ç¼è¡”æ¥** - æ”¯æŒä¸­æ–­åç»§ç»­ä¸‹è½½
- âœ… **ç‹¬ç«‹å…ƒæ•°æ®ç®¡ç†** - ä¸‹è½½çŠ¶æ€ä¸å®é™…æ–‡ä»¶åˆ†ç¦»å­˜å‚¨
- âœ… **è¶…å¤§æ–‡ä»¶å¤„ç†** - å•ç‹¬å¤„ç†è¶…è¿‡å­˜å‚¨é™åˆ¶çš„æ–‡ä»¶
- âœ… **ç©ºé—´å®‰å…¨ä¿æŠ¤** - è‡ªåŠ¨é¢„ç•™å®‰å…¨ä½™é‡
- âœ… **è¿›åº¦å®Œæ•´è·Ÿè¸ª** - æ‰¹æ¬¡çº§åˆ«å’Œæ–‡ä»¶çº§åˆ«åŒé‡è·Ÿè¸ª

## ğŸ“‹ å®Œæ•´å·¥ä½œæµç¨‹

### æ­¥éª¤1: åˆ†ææ•°æ®é›†
```bash
# åˆ†æ30TBæ•°æ®é›†çš„ç»“æ„
python main.py analyze-dataset large-model/30tb-dataset --dataset
```

**è¾“å‡ºç¤ºä¾‹:**
```
=== æ•°æ®é›†åˆ†æç»“æœ ===
æ€»æ–‡ä»¶æ•°: 15,420
æ€»å¤§å°: 30.2 TB

=== æ–‡ä»¶ç±»å‹åˆ†å¸ƒ ===
.safetensors      8,245 ä¸ªæ–‡ä»¶     28.5 TB
.json               156 ä¸ªæ–‡ä»¶      1.2 GB
.txt                 89 ä¸ªæ–‡ä»¶      125 MB
```

### æ­¥éª¤2: è§„åˆ’åˆ†æ‰¹ç­–ç•¥
```bash
# è§„åˆ’åˆ†æ‰¹ä¸‹è½½ (10TBå¯ç”¨ç©ºé—´)
python main.py plan-batch large-model/30tb-dataset \
  --available-space 10995116277760 \
  --dataset \
  --safety-margin 0.9
```

**è¾“å‡ºç¤ºä¾‹:**
```
=== åˆ†æ‰¹ä¸‹è½½è§„åˆ’ ===
æ•°æ®é›†æ€»å¤§å°: 30.2 TB
å¯ç”¨ç©ºé—´: 10.0 TB
å®‰å…¨å¯ç”¨ç©ºé—´: 9.0 TB (é¢„ç•™10%å®‰å…¨ä½™é‡)
éœ€è¦åˆ† 4 æ‰¹æ¬¡ä¸‹è½½
  æ‰¹æ¬¡ 1: 1,245 ä¸ªæ–‡ä»¶, 8.9 TB
  æ‰¹æ¬¡ 2: 1,356 ä¸ªæ–‡ä»¶, 8.8 TB
  æ‰¹æ¬¡ 3: 1,289 ä¸ªæ–‡ä»¶, 8.7 TB
  æ‰¹æ¬¡ 4: 11,530 ä¸ªæ–‡ä»¶, 3.8 TB

=== ç£ç›˜ç®¡ç†å»ºè®® ===
ğŸ’¡ å»ºè®®æ¯å®Œæˆ2-3ä¸ªæ‰¹æ¬¡åè¿›è¡Œä¸€æ¬¡æ–‡ä»¶å¤‡ä»½å’Œæ¸…ç†
â„¹ æ£€æµ‹åˆ° 12 ä¸ªè¶…å¤§æ–‡ä»¶éœ€è¦å•ç‹¬å¤„ç†

=== ç£ç›˜ä½¿ç”¨æ—¶é—´çº¿ ===
æ‰¹æ¬¡  1: 1245 æ–‡ä»¶, å½“å‰æ‰¹æ¬¡    8.9 TB, ç´¯è®¡    8.9 TB
æ‰¹æ¬¡  2: 1356 æ–‡ä»¶, å½“å‰æ‰¹æ¬¡    8.8 TB, ç´¯è®¡   17.7 TB
æ‰¹æ¬¡  3: 1289 æ–‡ä»¶, å½“å‰æ‰¹æ¬¡    8.7 TB, ç´¯è®¡   26.4 TB
æ‰¹æ¬¡  4:11530 æ–‡ä»¶, å½“å‰æ‰¹æ¬¡    3.8 TB, ç´¯è®¡   30.2 TB

é¢„è®¡å³°å€¼ç£ç›˜ä½¿ç”¨: 8.9 TB
```

### æ­¥éª¤3: æ‰§è¡Œç¬¬ä¸€æ‰¹æ¬¡
```bash
# å¼€å§‹åˆ†æ‰¹ä¸‹è½½
python main.py batch-download large-model/30tb-dataset \
  --available-space 10995116277760 \
  --dataset \
  --tool aria2c
```

**ç³»ç»Ÿä¼šè‡ªåŠ¨:**
1. åˆ›å»ºä¸‹è½½ä»»åŠ¡
2. æ£€æŸ¥ç³»ç»ŸçŠ¶æ€ï¼ˆç£ç›˜ã€ç½‘ç»œã€æƒé™ï¼‰
3. ä¸‹è½½ç¬¬ä¸€æ‰¹æ¬¡ï¼ˆ1,245ä¸ªæ–‡ä»¶ï¼Œ8.9TBï¼‰
4. éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
5. æ˜¾ç¤ºä¸‹ä¸€æ­¥æ“ä½œæŒ‡å—

### æ­¥éª¤4: æ¢ç›˜å’Œç»§ç»­ä¸‹è½½
```bash
# ç¬¬ä¸€æ‰¹æ¬¡å®Œæˆåçš„æ“ä½œ
# 1. å¤‡ä»½/ç§»åŠ¨ç¬¬ä¸€æ‰¹æ¬¡æ–‡ä»¶åˆ°å¤–éƒ¨å­˜å‚¨
mv downloads/large-model/30tb-dataset /external/storage/batch1/

# 2. æ¸…ç†ç©ºé—´å‡†å¤‡ä¸‹ä¸€æ‰¹æ¬¡
rm -rf downloads/large-model/30tb-dataset/*

# 3. ç»§ç»­ä¸‹è½½ç¬¬äºŒæ‰¹æ¬¡
python main.py batch-continue task_abc123 2
```

### æ­¥éª¤5: æŸ¥çœ‹è¿›åº¦å’ŒçŠ¶æ€
```bash
# æŸ¥çœ‹åˆ†æ‰¹ä¸‹è½½çŠ¶æ€
python main.py batch-status task_abc123

# æŸ¥çœ‹ä»»åŠ¡è¯¦æƒ…
python main.py task-detail task_abc123

# æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€
python main.py check-system
```

## ğŸ›¡ï¸ å®‰å…¨ç‰¹æ€§

### 1. ç£ç›˜ç©ºé—´ä¿æŠ¤
- **å®‰å…¨ä½™é‡**: é»˜è®¤é¢„ç•™10%ç©ºé—´ï¼Œå¯è°ƒæ•´
- **å®æ—¶ç›‘æ§**: æ¯ä¸ªæ‰¹æ¬¡ä¸‹è½½å‰æ£€æŸ¥å¯ç”¨ç©ºé—´
- **è‡ªåŠ¨åœæ­¢**: ç©ºé—´ä¸è¶³æ—¶è‡ªåŠ¨åœæ­¢ä¸‹è½½

### 2. å…ƒæ•°æ®ç‹¬ç«‹å­˜å‚¨
```
metadata/
â”œâ”€â”€ tasks/
â”‚   â””â”€â”€ task_abc123/
â”‚       â”œâ”€â”€ batch_progress.json      # æ‰¹æ¬¡è¿›åº¦
â”‚       â”œâ”€â”€ file_list.json          # å®Œæ•´æ–‡ä»¶åˆ—è¡¨
â”‚       â”œâ”€â”€ file_status.json        # æ–‡ä»¶ä¸‹è½½çŠ¶æ€
â”‚       â””â”€â”€ task_metadata.json      # ä»»åŠ¡å…ƒæ•°æ®
â””â”€â”€ batch_plan_large-model_30tb-dataset.json  # åˆ†æ‰¹è§„åˆ’
```

### 3. æ–­ç‚¹ç»­ä¼ æ”¯æŒ
- **æ–‡ä»¶çº§è·Ÿè¸ª**: æ¯ä¸ªæ–‡ä»¶çš„ä¸‹è½½çŠ¶æ€ç‹¬ç«‹è·Ÿè¸ª
- **æ‰¹æ¬¡çº§æ¢å¤**: æ”¯æŒä»ä»»æ„æ‰¹æ¬¡å¼€å§‹ç»§ç»­
- **çŠ¶æ€æŒä¹…åŒ–**: æ‰€æœ‰çŠ¶æ€ä¿¡æ¯æŒä¹…ä¿å­˜

## ğŸ›ï¸ é«˜çº§é…ç½®

### è‡ªå®šä¹‰å­˜å‚¨è·¯å¾„
```bash
# å°†å…ƒæ•°æ®å­˜å‚¨åˆ°SSDï¼Œä¸‹è½½æ–‡ä»¶å­˜å‚¨åˆ°æœºæ¢°ç¡¬ç›˜
python main.py \
  --metadata-dir /fast/ssd/metadata \
  --downloads-dir /large/hdd/downloads \
  batch-download large-model/30tb-dataset \
  --available-space 10995116277760 \
  --dataset
```

### è‡ªåŠ¨åŒ–æ‰¹æ¬¡å¤„ç†
```bash
# è‡ªåŠ¨æ‰§è¡Œæ‰€æœ‰æ‰¹æ¬¡ï¼ˆéœ€è¦å……è¶³ç©ºé—´ï¼‰
python main.py batch-download large-model/30tb-dataset \
  --available-space 10995116277760 \
  --dataset \
  --auto-proceed
```

### è°ƒæ•´å®‰å…¨ç­–ç•¥
```bash
# æ›´ä¸¥æ ¼çš„å®‰å…¨ä½™é‡ï¼ˆé¢„ç•™20%ï¼‰
python main.py plan-batch large-model/30tb-dataset \
  --available-space 10995116277760 \
  --dataset \
  --safety-margin 0.8
```

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. å¤§æ•°æ®é›†ä¸‹è½½ç­–ç•¥
```bash
# å¯¹äºè¶…å¤§æ•°æ®é›†ï¼Œå»ºè®®çš„å®Œæ•´æµç¨‹ï¼š

# Step 1: åˆ†æå’Œè§„åˆ’
python main.py analyze-dataset your-model/huge-dataset --dataset
python main.py plan-batch your-model/huge-dataset --available-space YOUR_SPACE --dataset

# Step 2: å‡†å¤‡ä¸“ç”¨ç›®å½•
mkdir -p /data/batch_downloads
mkdir -p /backup/completed_batches

# Step 3: æ‰§è¡Œåˆ†æ‰¹ä¸‹è½½
python main.py --downloads-dir /data/batch_downloads \
  batch-download your-model/huge-dataset \
  --available-space YOUR_SPACE --dataset

# Step 4: å¾ªç¯å¤„ç†æ¯ä¸ªæ‰¹æ¬¡
for batch in {2..N}; do
  # å¤‡ä»½å®Œæˆçš„æ‰¹æ¬¡
  mv /data/batch_downloads/* /backup/completed_batches/batch_$((batch-1))/
  
  # ç»§ç»­ä¸‹ä¸€æ‰¹æ¬¡
  python main.py --downloads-dir /data/batch_downloads \
    batch-continue task_id $batch
  
  # éªŒè¯å®Œæ•´æ€§
  python main.py verify task_id
done
```

### 2. æ¢ç›˜åœºæ™¯å¤„ç†
```bash
#!/bin/bash
# è‡ªåŠ¨åŒ–æ¢ç›˜è„šæœ¬ç¤ºä¾‹

TASK_ID="your_task_id"
CURRENT_BATCH=1
TOTAL_BATCHES=4

for ((batch=$CURRENT_BATCH; batch<=TOTAL_BATCHES; batch++)); do
  echo "å¤„ç†æ‰¹æ¬¡ $batch/$TOTAL_BATCHES"
  
  # ä¸‹è½½å½“å‰æ‰¹æ¬¡
  python main.py batch-continue $TASK_ID $batch
  
  if [ $? -eq 0 ]; then
    echo "æ‰¹æ¬¡ $batch ä¸‹è½½å®Œæˆ"
    
    # å¤‡ä»½åˆ°å¤–éƒ¨å­˜å‚¨
    echo "æ­£åœ¨å¤‡ä»½æ‰¹æ¬¡ $batch..."
    rsync -av downloads/ /external/storage/batch_$batch/
    
    if [ $batch -lt $TOTAL_BATCHES ]; then
      echo "è¯·æ›´æ¢å­˜å‚¨è®¾å¤‡åæŒ‰å›è½¦ç»§ç»­..."
      read -p "å‡†å¤‡å¥½ç»§ç»­ä¸‹ä¸€æ‰¹æ¬¡äº†å—? (y/n): " confirm
      
      if [[ $confirm == [yY] ]]; then
        # æ¸…ç†å½“å‰æ‰¹æ¬¡æ–‡ä»¶ä¸ºä¸‹ä¸€æ‰¹æ¬¡è…¾å‡ºç©ºé—´
        rm -rf downloads/*
        echo "å·²æ¸…ç†ç©ºé—´ï¼Œå‡†å¤‡ä¸‹è½½æ‰¹æ¬¡ $((batch+1))"
      else
        echo "ç”¨æˆ·å–æ¶ˆï¼Œé€€å‡º"
        break
      fi
    fi
  else
    echo "æ‰¹æ¬¡ $batch ä¸‹è½½å¤±è´¥ï¼Œé€€å‡º"
    break
  fi
done

echo "åˆ†æ‰¹ä¸‹è½½å®Œæˆï¼"
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

1. **æ‰¹æ¬¡ä¸­æ–­åå¦‚ä½•æ¢å¤ï¼Ÿ**
   ```bash
   # æŸ¥çœ‹æ‰¹æ¬¡çŠ¶æ€
   python main.py batch-status task_id
   
   # ä»æŒ‡å®šæ‰¹æ¬¡ç»§ç»­
   python main.py batch-continue task_id 3
   ```

2. **ä¿®æ”¹æ‰¹æ¬¡è§„åˆ’æ€ä¹ˆåŠï¼Ÿ**
   ```bash
   # é‡æ–°è§„åˆ’ï¼ˆä¼šè¦†ç›–åŸæœ‰è§„åˆ’ï¼‰
   python main.py plan-batch dataset-id --available-space NEW_SIZE --dataset
   ```

3. **éªŒè¯å·²ä¸‹è½½æ–‡ä»¶çš„å®Œæ•´æ€§ï¼Ÿ**
   ```bash
   # éªŒè¯ç‰¹å®šä»»åŠ¡çš„æ–‡ä»¶
   python main.py verify task_id
   ```

4. **æ¸…ç†ä¸­é—´çŠ¶æ€ï¼Ÿ**
   ```bash
   # æ¸…ç†å®Œæˆçš„ä»»åŠ¡è®°å½•
   python main.py clean
   
   # æ‰‹åŠ¨æ¸…ç†ç‰¹å®šä»»åŠ¡çš„å…ƒæ•°æ®
   rm -rf metadata/tasks/task_id
   ```

## ğŸ“Š æ€§èƒ½å»ºè®®

### å­˜å‚¨ä¼˜åŒ–
- **SSDç”¨äºå…ƒæ•°æ®**: å°†`--metadata-dir`æŒ‡å‘SSDæå‡å“åº”é€Ÿåº¦
- **æœºæ¢°ç¡¬ç›˜ç”¨äºä¸‹è½½**: å°†`--downloads-dir`æŒ‡å‘å¤§å®¹é‡æœºæ¢°ç¡¬ç›˜
- **ç½‘ç»œå­˜å‚¨**: æ”¯æŒNFSã€CIFSç­‰ç½‘ç»œå­˜å‚¨

### ç½‘ç»œä¼˜åŒ–
- **å¹¶å‘ä¸‹è½½**: è°ƒæ•´`-j`å‚æ•°æ§åˆ¶å¹¶å‘æ•°
- **è¿æ¥æ•°**: è°ƒæ•´`-x`å‚æ•°æ§åˆ¶æ¯æ–‡ä»¶è¿æ¥æ•°
- **ä»£ç†è®¾ç½®**: æ”¯æŒHTTP/HTTPSä»£ç†

### ç›‘æ§å’Œæ—¥å¿—
- **å®æ—¶ç›‘æ§**: `python main.py check-system`
- **è¯¦ç»†æ—¥å¿—**: æŸ¥çœ‹`logs/dataset_manager.log`
- **è¿›åº¦è·Ÿè¸ª**: `python main.py batch-status task_id`

---

ğŸ‰ **æ­å–œï¼** æ‚¨ç°åœ¨æ‹¥æœ‰äº†ä¸€ä¸ªå¼ºå¤§çš„åˆ†æ‰¹ä¸‹è½½ç³»ç»Ÿï¼Œå¯ä»¥è½»æ¾å¤„ç†ä»»æ„å¤§å°çš„æ•°æ®é›†ä¸‹è½½ï¼Œå®Œç¾è§£å†³äº†å­˜å‚¨ç©ºé—´é™åˆ¶çš„é—®é¢˜ï¼ 