#!/usr/bin/env python3
"""
HFD å…ƒæ•°æ®å¯¼å…¥å·¥å…·
å°† hfd ä¸‹è½½çš„å…ƒæ•°æ®å¯¼å…¥åˆ°æˆ‘ä»¬çš„æ•°æ®é›†ä¸‹è½½ç®¡ç†ç³»ç»Ÿä¸­
"""

import os
import json
import sys
import re
from pathlib import Path
from urllib.parse import urlparse
from typing import Dict, List, Optional, Tuple
import argparse

from task_manager import TaskManager


class HFDImporter:
    """HFD å…ƒæ•°æ®å¯¼å…¥å™¨"""
    
    def __init__(self, hfd_dir: str, output_dir: str, base_url: str = "https://hf-mirror.com"):
        self.hfd_dir = Path(hfd_dir)
        self.output_dir = Path(output_dir)  
        self.base_url = base_url
        
        # æ£€æŸ¥å¿…è¦æ–‡ä»¶
        self.aria2c_urls_file = self.hfd_dir / "aria2c_urls.txt"
        self.repo_metadata_file = self.hfd_dir / "repo_metadata.json"
        self.last_command_file = self.hfd_dir / "last_download_command"
        
        if not self.aria2c_urls_file.exists():
            raise FileNotFoundError(f"aria2c_urls.txt æ–‡ä»¶ä¸å­˜åœ¨: {self.aria2c_urls_file}")
        if not self.repo_metadata_file.exists():
            raise FileNotFoundError(f"repo_metadata.json æ–‡ä»¶ä¸å­˜åœ¨: {self.repo_metadata_file}")
            
    def parse_aria2c_urls(self) -> List[Dict]:
        """è§£æ aria2c_urls.txt æ–‡ä»¶"""
        files = []
        current_file = {}
        
        with open(self.aria2c_urls_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            
        i = 0
        while i < len(lines):
            line = lines[i].strip()
            
            if line.startswith('https://'):
                # å¦‚æœå‰é¢æœ‰æ–‡ä»¶æ•°æ®ï¼Œå…ˆä¿å­˜
                if current_file:
                    files.append(current_file.copy())
                
                # å¼€å§‹æ–°æ–‡ä»¶ï¼Œæ¸…ç†URLï¼ˆç§»é™¤å¯èƒ½çš„åˆ¶è¡¨ç¬¦ç­‰ï¼‰
                url = line.strip()
                current_file = {'url': url}
                
                # å¤„ç†åç»­çš„é…ç½®è¡Œ
                i += 1
                while i < len(lines):
                    config_line = lines[i].strip()
                    
                    # å¦‚æœæ˜¯ä¸‹ä¸€ä¸ªURLï¼Œé€€å‡ºå†…å±‚å¾ªç¯
                    if config_line.startswith('https://'):
                        i -= 1  # å›é€€ä¸€è¡Œï¼Œè®©å¤–å±‚å¾ªç¯å¤„ç†
                        break
                    
                    # è§£æé…ç½®è¡Œ
                    if config_line.startswith('gid='):
                        current_file['gid'] = config_line.split('=', 1)[1]
                    elif config_line.startswith('dir='):
                        current_file['dir'] = config_line.split('=', 1)[1]
                    elif config_line.startswith('out='):
                        current_file['out'] = config_line.split('=', 1)[1]
                    
                    i += 1
                i -= 1  # å›é€€ä¸€è¡Œï¼Œå› ä¸ºä¸‹æ¬¡å¤–å±‚å¾ªç¯ä¼š+1
                
            i += 1
            
        # æ·»åŠ æœ€åä¸€ä¸ªæ–‡ä»¶
        if current_file:
            files.append(current_file)
            
        return files
        
    def parse_repo_metadata(self) -> Dict:
        """è§£æ repo_metadata.json æ–‡ä»¶"""
        with open(self.repo_metadata_file, 'r', encoding='utf-8') as f:
            return json.load(f)
            
    def parse_last_command(self) -> Dict:
        """è§£æ last_download_command æ–‡ä»¶"""
        command_info = {}
        if self.last_command_file.exists():
            with open(self.last_command_file, 'r', encoding='utf-8') as f:
                content = f.read().strip()
                # è§£æç¯å¢ƒå˜é‡æ ¼å¼
                for pair in content.split():
                    if '=' in pair:
                        key, value = pair.split('=', 1)
                        command_info[key] = value
        return command_info
        
    def get_file_status(self, file_path: Path) -> str:
        """æ£€æŸ¥æ–‡ä»¶ä¸‹è½½çŠ¶æ€"""
        if not file_path.exists():
            return "pending"
            
        # æ£€æŸ¥ .aria2 æ–‡ä»¶ï¼ˆæœªå®Œæˆæ ‡å¿—ï¼‰
        aria2_file = Path(str(file_path) + '.aria2')
        if aria2_file.exists():
            return "downloading"
            
        return "completed"
        
    def convert_to_our_format(self) -> Tuple[Dict, List[Dict]]:
        """è½¬æ¢ä¸ºæˆ‘ä»¬ç³»ç»Ÿçš„æ ¼å¼"""
        # è§£ææ•°æ®
        aria2c_files = self.parse_aria2c_urls()
        repo_metadata = self.parse_repo_metadata()
        command_info = self.parse_last_command()
        
        # åˆ›å»ºä»»åŠ¡ä¿¡æ¯
        repo_id = command_info.get('REPO_ID', repo_metadata.get('id', 'unknown'))
        
        task_info = {
            'repo_id': repo_id,
            'task_name': f"hfd_import_{repo_id.replace('/', '_')}",
            'base_url': self.base_url,
            'output_dir': str(self.output_dir),
            'created_from_hfd': True,
            'hfd_metadata': {
                'original_hfd_dir': str(self.hfd_dir),
                'repo_metadata': repo_metadata,
                'command_info': command_info,
                'import_time': None  # ä¼šåœ¨å¯¼å…¥æ—¶è®¾ç½®
            }
        }
        
        # è½¬æ¢æ–‡ä»¶åˆ—è¡¨
        file_list = []
        for file_info in aria2c_files:
            url = file_info['url']
            file_dir = file_info.get('dir', '')
            filename = file_info.get('out', '')
            
            # æ„å»ºå®Œæ•´çš„æ–‡ä»¶è·¯å¾„
            if file_dir:
                relative_path = f"{file_dir}/{filename}"
            else:
                relative_path = filename
                
            full_path = self.output_dir / relative_path
            
            # è·å–æ–‡ä»¶çŠ¶æ€
            status = self.get_file_status(full_path)
            
            file_entry = {
                'url': url,
                'relative_path': relative_path,
                'full_path': str(full_path),
                'status': status,
                'gid': file_info.get('gid'),
                'from_hfd': True
            }
            
            file_list.append(file_entry)
            
        return task_info, file_list
        
    def import_to_system(self, task_manager: TaskManager) -> str:
        """å¯¼å…¥åˆ°ç³»ç»Ÿä¸­"""
        # è½¬æ¢æ•°æ®
        task_info, file_list = self.convert_to_our_format()
        
        # è®¾ç½®å¯¼å…¥æ—¶é—´
        import datetime
        task_info['hfd_metadata']['import_time'] = datetime.datetime.now().isoformat()
        
        # åˆ›å»ºä»»åŠ¡ï¼Œä½¿ç”¨TaskManagerç°æœ‰çš„æ¥å£
        task_id = task_manager.create_task(
            repo_id=task_info['repo_id'],
            local_dir=task_info['output_dir'],
            is_dataset=True  # HFDé€šå¸¸ç”¨äºæ•°æ®é›†
        )
        
        # è·å–ä»»åŠ¡å¹¶æ·»åŠ HFDç‰¹æœ‰çš„å…ƒæ•°æ®
        task = task_manager.get_task(task_id)
        if task:
            # å°†HFDå…ƒæ•°æ®å­˜å‚¨åœ¨ä»»åŠ¡ä¸­
            task['hfd_metadata'] = task_info['hfd_metadata']
            task['created_from_hfd'] = True
            task['base_url'] = task_info['base_url']
            task['total_files'] = len(file_list)
            
            # ç»Ÿè®¡æ–‡ä»¶çŠ¶æ€
            status_counts = {}
            for file_entry in file_list:
                status = file_entry['status']
                status_counts[status] = status_counts.get(status, 0) + 1
            
            # è®¡ç®—è¿›åº¦
            completed_files = status_counts.get('completed', 0)
            if len(file_list) > 0:
                progress = f"{completed_files * 100 // len(file_list)}%"
                task['progress'] = progress
            
            # æ›´æ–°ä»»åŠ¡
            task_manager._save_tasks()
            
            # TODO: è¿™é‡Œåº”è¯¥è¿˜éœ€è¦å°†æ–‡ä»¶åˆ—è¡¨ä¿å­˜åˆ°æŸä¸ªåœ°æ–¹
            # ç›®å‰æˆ‘ä»¬å°†æ–‡ä»¶ä¿¡æ¯ä¿å­˜åœ¨ä»»åŠ¡çš„metadataä¸­
            task['hfd_files'] = file_list
            task_manager._save_tasks()
            
        return task_id
        
    def print_summary(self):
        """æ‰“å°å¯¼å…¥æ‘˜è¦"""
        task_info, file_list = self.convert_to_our_format()
        
        print(f"ğŸ“Š HFD å¯¼å…¥æ‘˜è¦")
        print(f"ğŸ“ ä»“åº“ID: {task_info['repo_id']}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {task_info['output_dir']}")
        print(f"ğŸŒ åŸºç¡€URL: {task_info['base_url']}")
        print(f"ğŸ“ åŸå§‹HFDç›®å½•: {task_info['hfd_metadata']['original_hfd_dir']}")
        print()
        
        # ç»Ÿè®¡æ–‡ä»¶çŠ¶æ€
        status_count = {}
        for file_entry in file_list:
            status = file_entry['status']
            status_count[status] = status_count.get(status, 0) + 1
            
        print(f"ğŸ“‹ æ–‡ä»¶çŠ¶æ€ç»Ÿè®¡:")
        for status, count in status_count.items():
            status_name = {
                'completed': 'âœ… å·²å®Œæˆ',
                'downloading': 'â¬ ä¸‹è½½ä¸­',
                'pending': 'â³ å¾…ä¸‹è½½'
            }.get(status, status)
            print(f"  {status_name}: {count} ä¸ªæ–‡ä»¶")
            
        print(f"ğŸ“ æ€»æ–‡ä»¶æ•°: {len(file_list)}")
        
        # æ˜¾ç¤ºå‰å‡ ä¸ªæ–‡ä»¶çš„ç¤ºä¾‹
        print(f"\nğŸ“‹ æ–‡ä»¶ç¤ºä¾‹ (å‰5ä¸ª):")
        for i, file_entry in enumerate(file_list[:5]):
            status_icon = {
                'completed': 'âœ…',
                'downloading': 'â¬', 
                'pending': 'â³'
            }.get(file_entry['status'], 'â“')
            print(f"  {status_icon} {file_entry['relative_path']}")
            
        if len(file_list) > 5:
            print(f"  ... è¿˜æœ‰ {len(file_list) - 5} ä¸ªæ–‡ä»¶")


def main():
    parser = argparse.ArgumentParser(description='HFD å…ƒæ•°æ®å¯¼å…¥å·¥å…·')
    parser.add_argument('hfd_dir', help='HFD å…ƒæ•°æ®ç›®å½•è·¯å¾„ (åŒ…å« .hfd ç›®å½•)')
    parser.add_argument('output_dir', help='æ•°æ®é›†è¾“å‡ºç›®å½•')
    parser.add_argument('--base-url', default='https://hf-mirror.com', help='åŸºç¡€URL (é»˜è®¤: https://hf-mirror.com)')
    parser.add_argument('--dry-run', action='store_true', help='åªæ˜¾ç¤ºæ‘˜è¦ï¼Œä¸å®é™…å¯¼å…¥')
    parser.add_argument('--db-path', default='downloads.db', help='æ•°æ®åº“æ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    try:
        # æŸ¥æ‰¾ .hfd ç›®å½•
        hfd_dir = Path(args.hfd_dir)
        if hfd_dir.name == '.hfd':
            hfd_metadata_dir = hfd_dir
        else:
            hfd_metadata_dir = hfd_dir / '.hfd'
            
        if not hfd_metadata_dir.exists():
            print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ° .hfd ç›®å½•: {hfd_metadata_dir}")
            sys.exit(1)
            
        # åˆ›å»ºå¯¼å…¥å™¨
        importer = HFDImporter(
            hfd_dir=str(hfd_metadata_dir),
            output_dir=args.output_dir,
            base_url=args.base_url
        )
        
        # æ˜¾ç¤ºæ‘˜è¦
        importer.print_summary()
        
        if args.dry_run:
            print("\nğŸ” è¿™æ˜¯è¯•è¿è¡Œæ¨¡å¼ï¼Œæœªå®é™…å¯¼å…¥æ•°æ®")
            return
            
        # ç¡®è®¤å¯¼å…¥
        print(f"\nâ“ æ˜¯å¦è¦å°†è¿™ä¸ª HFD ä»»åŠ¡å¯¼å…¥åˆ°æ•°æ®åº“ï¼Ÿ (y/N): ", end='')
        response = input().strip().lower()
        
        if response in ['y', 'yes']:
            # æ‰§è¡Œå¯¼å…¥
            task_manager = TaskManager(args.db_path)
            task_id = importer.import_to_system(task_manager)
            
            print(f"\nâœ… å¯¼å…¥æˆåŠŸï¼")
            print(f"ğŸ“‹ ä»»åŠ¡ID: {task_id}")
            print(f"ğŸ’¾ æ•°æ®åº“: {args.db_path}")
            print(f"\nğŸš€ ä½ ç°åœ¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ç»§ç»­ä¸‹è½½:")
            print(f"   python main.py --resume --task-id {task_id}")
            
        else:
            print("\nâŒ å¯¼å…¥å·²å–æ¶ˆ")
            
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main() 