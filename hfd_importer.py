#!/usr/bin/env python3
"""
HFD å…ƒæ•°æ®å¯¼å…¥å·¥å…·
å°† hfd ä¸‹è½½çš„å…ƒæ•°æ®å¯¼å…¥åˆ°æˆ‘ä»¬çš„æ•°æ®é›†ä¸‹è½½ç®¡ç†ç³»ç»Ÿä¸­
"""

import os
import json
import sys
import re
from pathlib import Path
from urllib.parse import urlparse
from typing import Dict, List, Optional, Tuple, Set
import argparse

from task_manager import TaskManager
from utils import get_current_timestamp, format_file_size


class HFDImporter:
    """HFD å…ƒæ•°æ®å¯¼å…¥å™¨"""
    
    def __init__(self, hfd_dir: str, output_dir: str, base_url: str = "https://hf-mirror.com"):
        self.hfd_dir = Path(hfd_dir)
        self.output_dir = Path(output_dir)  
        self.base_url = base_url
        
        # æ£€æŸ¥å¿…è¦æ–‡ä»¶
        self.aria2c_urls_file = self.hfd_dir / "aria2c_urls.txt"
        self.repo_metadata_file = self.hfd_dir / "repo_metadata.json"
        self.last_command_file = self.hfd_dir / "last_download_command"
        
        if not self.aria2c_urls_file.exists():
            raise FileNotFoundError(f"aria2c_urls.txt æ–‡ä»¶ä¸å­˜åœ¨: {self.aria2c_urls_file}")
        if not self.repo_metadata_file.exists():
            raise FileNotFoundError(f"repo_metadata.json æ–‡ä»¶ä¸å­˜åœ¨: {self.repo_metadata_file}")
            
    def parse_aria2c_urls(self) -> Dict[str, Dict]:
        """è§£æ aria2c_urls.txt æ–‡ä»¶ï¼Œè¿”å›æ–‡ä»¶è·¯å¾„åˆ°ä¸‹è½½é…ç½®çš„æ˜ å°„"""
        aria2c_files = {}
        current_file = {}
        
        with open(self.aria2c_urls_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            
        i = 0
        while i < len(lines):
            line = lines[i].strip()
            
            if line.startswith('https://'):
                # å¦‚æœå‰é¢æœ‰æ–‡ä»¶æ•°æ®ï¼Œå…ˆä¿å­˜
                if current_file and 'out' in current_file and 'dir' in current_file:
                    # æ„å»ºç›¸å¯¹è·¯å¾„ä½œä¸ºkey
                    relative_path = f"{current_file['dir']}/{current_file['out']}"
                    aria2c_files[relative_path] = current_file.copy()
                
                # å¼€å§‹æ–°æ–‡ä»¶ï¼Œæ¸…ç†URLï¼ˆç§»é™¤å¯èƒ½çš„åˆ¶è¡¨ç¬¦ç­‰ï¼‰
                url = line.strip()
                current_file = {'url': url}
                
                # å¤„ç†åç»­çš„é…ç½®è¡Œ
                i += 1
                while i < len(lines):
                    config_line = lines[i].strip()
                    
                    # å¦‚æœæ˜¯ä¸‹ä¸€ä¸ªURLï¼Œé€€å‡ºå†…å±‚å¾ªç¯
                    if config_line.startswith('https://'):
                        i -= 1  # å›é€€ä¸€è¡Œï¼Œè®©å¤–å±‚å¾ªç¯å¤„ç†
                        break
                    
                    # è§£æé…ç½®è¡Œ
                    if '=' in config_line:
                        key, value = config_line.split('=', 1)
                        current_file[key] = value
                    
                    i += 1
                i -= 1  # å›é€€ä¸€è¡Œï¼Œå› ä¸ºä¸‹æ¬¡å¤–å±‚å¾ªç¯ä¼š+1
                
            i += 1
            
        # æ·»åŠ æœ€åä¸€ä¸ªæ–‡ä»¶
        if current_file and 'out' in current_file and 'dir' in current_file:
            relative_path = f"{current_file['dir']}/{current_file['out']}"
            aria2c_files[relative_path] = current_file
            
        return aria2c_files
        
    def parse_repo_metadata(self) -> Dict:
        """è§£æ repo_metadata.json æ–‡ä»¶"""
        with open(self.repo_metadata_file, 'r', encoding='utf-8') as f:
            return json.load(f)
            
    def parse_last_command(self) -> Dict:
        """è§£æ last_download_command æ–‡ä»¶"""
        command_info = {}
        if self.last_command_file.exists():
            with open(self.last_command_file, 'r', encoding='utf-8') as f:
                content = f.read().strip()
                # è§£æç¯å¢ƒå˜é‡æ ¼å¼
                for pair in content.split():
                    if '=' in pair:
                        key, value = pair.split('=', 1)
                        command_info[key] = value
        return command_info
        
    def get_file_status(self, file_path: Path, is_in_aria2c_urls: bool) -> str:
        """æ£€æŸ¥æ–‡ä»¶ä¸‹è½½çŠ¶æ€
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            is_in_aria2c_urls: æ–‡ä»¶æ˜¯å¦åœ¨aria2c_urls.txtä¸­ï¼ˆç­‰å¾…ä¸‹è½½åˆ—è¡¨ï¼‰
        """
        # å¦‚æœæ–‡ä»¶åœ¨aria2c_urls.txtä¸­ï¼Œè¯´æ˜å®ƒæ˜¯ç­‰å¾…ä¸‹è½½çš„
        if is_in_aria2c_urls:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not file_path.exists():
                return "pending"
            
            # æ£€æŸ¥ .aria2 æ–‡ä»¶ï¼ˆä¸‹è½½ä¸­æ ‡å¿—ï¼‰
            aria2_file = Path(str(file_path) + '.aria2')
            if aria2_file.exists():
                return "downloading"
            
            # æ–‡ä»¶å­˜åœ¨ä¸”æ²¡æœ‰.aria2æ–‡ä»¶ï¼Œä½†ä»åœ¨ç­‰å¾…åˆ—è¡¨ä¸­ï¼Œå¯èƒ½æ˜¯åˆšå®Œæˆä½†aria2c_urls.txtè¿˜æ²¡æ›´æ–°
            return "completed"
        else:
            # ä¸åœ¨aria2c_urls.txtä¸­ï¼Œè¯´æ˜å·²ç»ä¸‹è½½å®Œæˆæˆ–ä¸éœ€è¦ä¸‹è½½
            if file_path.exists():
                return "completed"
            else:
                # è¿™ç§æƒ…å†µæ¯”è¾ƒç‰¹æ®Šï¼šä¸åœ¨ç­‰å¾…åˆ—è¡¨ä¸­ä½†æ–‡ä»¶ä¸å­˜åœ¨
                # å¯èƒ½æ˜¯å°æ–‡ä»¶ï¼ˆå¦‚.gitattributesï¼‰æˆ–è€…æœ‰å…¶ä»–é—®é¢˜
                return "missing"
        
    def create_complete_file_list(self) -> List[Dict]:
        """åˆ›å»ºå®Œæ•´çš„æ–‡ä»¶åˆ—è¡¨ï¼Œç»“åˆ aria2c_urls.txt å’Œ repo_metadata.json"""
        # è§£æä¸¤ä¸ªæ–‡ä»¶
        aria2c_files = self.parse_aria2c_urls()
        repo_metadata = self.parse_repo_metadata()
        
        print(f"\nğŸ“Š æ–‡ä»¶ç»Ÿè®¡:")
        print(f"  siblingsæ€»æ•°: {len(repo_metadata.get('siblings', []))}")
        print(f"  aria2cæ–‡ä»¶æ•°: {len(aria2c_files)}")
        
        # è·å–æ‰€æœ‰æ–‡ä»¶åˆ—è¡¨
        all_siblings = repo_metadata.get('siblings', [])
        
        # æ„å»ºå®Œæ•´æ–‡ä»¶åˆ—è¡¨
        complete_file_list = []
        aria2c_file_paths = set(aria2c_files.keys())
        
        # é¦–å…ˆå¤„ç†æ‰€æœ‰siblingsä¸­çš„æ–‡ä»¶
        for sibling in all_siblings:
            rfilename = sibling.get('rfilename', '')
            if not rfilename:
                continue
                
            # æ„å»ºå®Œæ•´è·¯å¾„
            full_path = self.output_dir / rfilename
            
            # æ£€æŸ¥è¿™ä¸ªæ–‡ä»¶æ˜¯å¦åœ¨ aria2c_urls.txt ä¸­
            has_download_config = rfilename in aria2c_file_paths
            
            # è·å–æ–‡ä»¶å¤§å°
            size = sibling.get('size', 0)
            
            if has_download_config:
                # æœ‰ä¸‹è½½é…ç½®çš„æ–‡ä»¶ï¼ˆå¾…ä¸‹è½½ï¼‰
                aria2c_config = aria2c_files[rfilename]
                file_entry = {
                    'filename': rfilename,
                    'url': aria2c_config.get('url', ''),
                    'size': size,
                    'status': 'pending',
                    'from_hfd': True
                }
            else:
                # æ²¡æœ‰ä¸‹è½½é…ç½®çš„æ–‡ä»¶ï¼ˆå·²å®Œæˆï¼‰
                # æ„é€ ä¸€ä¸ªåŸºæœ¬çš„URL
                repo_id = repo_metadata.get('id', 'unknown')
                url = f"{self.base_url}/datasets/{repo_id}/resolve/main/{rfilename}"
                
                file_entry = {
                    'filename': rfilename,
                    'url': url,
                    'size': size,
                    'status': 'completed',
                    'actual_size': size,  # å·²å®Œæˆæ–‡ä»¶çš„å®é™…å¤§å°å°±æ˜¯size
                    'downloaded_size': size,  # å·²å®Œæˆæ–‡ä»¶çš„ä¸‹è½½å¤§å°å°±æ˜¯size
                    'completed_at': get_current_timestamp(),
                    'from_hfd': True
                }
            
            complete_file_list.append(file_entry)
            
        # æ£€æŸ¥æ˜¯å¦æœ‰ aria2c_urls.txt ä¸­çš„æ–‡ä»¶æ²¡æœ‰åœ¨ siblings ä¸­
        sibling_paths = {s.get('rfilename', '') for s in all_siblings}
        missing_from_siblings = aria2c_file_paths - sibling_paths
        
        if missing_from_siblings:
            print(f"\nâš ï¸  è­¦å‘Š: å‘ç° {len(missing_from_siblings)} ä¸ªæ–‡ä»¶åœ¨ aria2c_urls.txt ä¸­ä½†ä¸åœ¨ repo_metadata.json çš„ siblings ä¸­")
            print(f"è¿™äº›æ–‡ä»¶ä¹Ÿä¼šè¢«æ·»åŠ åˆ°ä¸‹è½½åˆ—è¡¨ä¸­ã€‚")
                
            # æ·»åŠ è¿™äº›ç¼ºå¤±çš„æ–‡ä»¶
            for missing_path in missing_from_siblings:
                aria2c_config = aria2c_files[missing_path]
                full_path = self.output_dir / missing_path
                
                file_entry = {
                    'filename': missing_path,
                    'url': aria2c_config.get('url', ''),
                    'size': 0,  # å¤§å°æœªçŸ¥
                    'status': 'pending',
                    'from_hfd': True
                }
                complete_file_list.append(file_entry)
        
        print(f"  å®Œæ•´æ–‡ä»¶æ•°: {len(complete_file_list)}")
        
        # ç»Ÿè®¡çŠ¶æ€
        status_count = {'pending': 0, 'completed': 0}
        total_size = 0
        for file_entry in complete_file_list:
            status = file_entry['status']
            status_count[status] = status_count.get(status, 0) + 1
            if status == 'completed':
                total_size += file_entry.get('size', 0)
            
        print(f"  - å¾…ä¸‹è½½: {status_count['pending']} ä¸ªæ–‡ä»¶")
        print(f"  - å·²å®Œæˆ: {status_count['completed']} ä¸ªæ–‡ä»¶")
        print(f"  - å·²å®Œæˆå¤§å°: {total_size / (1024**3):.2f} GB")
        
        return complete_file_list
        
    def convert_to_our_format(self) -> Tuple[Dict, List[Dict]]:
        """è½¬æ¢ä¸ºæˆ‘ä»¬ç³»ç»Ÿçš„æ ¼å¼"""
        # è§£ææ•°æ®
        repo_metadata = self.parse_repo_metadata()
        command_info = self.parse_last_command()
        complete_file_list = self.create_complete_file_list()
        
        # åˆ›å»ºä»»åŠ¡ä¿¡æ¯
        repo_id = command_info.get('REPO_ID', repo_metadata.get('id', 'unknown'))
        
        task_info = {
            'repo_id': repo_id,
            'task_name': f"hfd_import_{repo_id.replace('/', '_')}",
            'base_url': self.base_url,
            'output_dir': str(self.output_dir),
            'created_from_hfd': True,
            'hfd_metadata': {
                'original_hfd_dir': str(self.hfd_dir),
                'repo_metadata': repo_metadata,
                'command_info': command_info,
                'import_time': None,  # ä¼šåœ¨å¯¼å…¥æ—¶è®¾ç½®
                'total_siblings': len(repo_metadata.get('siblings', [])),
                'aria2c_files_count': len(self.parse_aria2c_urls()),
                'complete_files_count': len(complete_file_list)
            }
        }
        
        return task_info, complete_file_list
        
    def import_to_system(self, task_manager: TaskManager) -> str:
        """å¯¼å…¥åˆ°ç³»ç»Ÿä¸­"""
        # è½¬æ¢æ•°æ®
        task_info, file_list = self.convert_to_our_format()
        
        # è®¾ç½®å¯¼å…¥æ—¶é—´
        import datetime
        task_info['hfd_metadata']['import_time'] = datetime.datetime.now().isoformat()
        
        # ç»Ÿè®¡æ–‡ä»¶çŠ¶æ€
        status_counts = {'pending': 0, 'completed': 0}
        total_size = 0
        for file_entry in file_list:
            status = file_entry.get('status', 'pending')
            status_counts[status] = status_counts.get(status, 0) + 1
            if status == 'completed':
                total_size += file_entry.get('size', 0)
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯åˆ°å…ƒæ•°æ®
        task_info['hfd_metadata'].update({
            'complete_files_count': len(file_list),
            'completed_files': status_counts['completed'],
            'pending_files': status_counts['pending'],
            'total_size': total_size,
            'total_size_formatted': format_file_size(total_size)
        })
        
        # åˆ›å»ºä»»åŠ¡ï¼Œä½¿ç”¨TaskManagerç°æœ‰çš„æ¥å£
        task_id = task_manager.create_task(
            repo_id=task_info['repo_id'],
            local_dir=task_info['output_dir'],
            is_dataset=True,  # HFDé€šå¸¸ç”¨äºæ•°æ®é›†
            hfd_metadata=task_info['hfd_metadata']  # ä¼ é€’HFDå…ƒæ•°æ®
        )
        
        # è·å–ä»»åŠ¡å¹¶æ·»åŠ HFDç‰¹æœ‰çš„å…ƒæ•°æ®
        task = task_manager.get_task(task_id)
        if task:
            # å°†HFDå…ƒæ•°æ®å­˜å‚¨åœ¨ä»»åŠ¡ä¸­
            task['hfd_metadata'] = task_info['hfd_metadata']
            task['created_from_hfd'] = True
            task['base_url'] = task_info['base_url']
            task['total_files'] = len(file_list)
            task['hfd_complete_files'] = file_list  # ä¿å­˜å®Œæ•´çš„æ–‡ä»¶åˆ—è¡¨
            
            # æ›´æ–°ä»»åŠ¡
            task_manager._save_tasks()
            
        return task_id
        
    def print_summary(self):
        """æ‰“å°å¯¼å…¥æ‘˜è¦"""
        task_info, file_list = self.convert_to_our_format()
        
        print(f"ğŸ“Š HFD å¯¼å…¥æ‘˜è¦")
        print(f"ğŸ“ ä»“åº“ID: {task_info['repo_id']}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {task_info['output_dir']}")
        print(f"ğŸŒ åŸºç¡€URL: {task_info['base_url']}")
        print(f"ğŸ“ åŸå§‹HFDç›®å½•: {task_info['hfd_metadata']['original_hfd_dir']}")
        print()
        
        hfd_meta = task_info['hfd_metadata']
        print(f"ğŸ“‹ æ–‡ä»¶ç»Ÿè®¡:")
        print(f"  ğŸ—‚ï¸  repo_metadata.json ä¸­çš„ siblings: {hfd_meta['total_siblings']} ä¸ª")
        print(f"  ğŸ“¥ aria2c_urls.txt ä¸­çš„ä¸‹è½½æ–‡ä»¶: {hfd_meta['aria2c_files_count']} ä¸ª")
        print(f"  ğŸ“ åˆå¹¶åçš„å®Œæ•´æ–‡ä»¶åˆ—è¡¨: {hfd_meta['complete_files_count']} ä¸ª")
        print()
        
        # ç»Ÿè®¡æ–‡ä»¶çŠ¶æ€
        status_count = {}
        download_config_count = {'with_config': 0, 'without_config': 0}
        
        for file_entry in file_list:
            status = file_entry['status']
            status_count[status] = status_count.get(status, 0) + 1
            
            if file_entry.get('has_download_config', False):
                download_config_count['with_config'] += 1
            else:
                download_config_count['without_config'] += 1
            
        print(f"ğŸ“‹ æ–‡ä»¶çŠ¶æ€ç»Ÿè®¡:")
        for status, count in status_count.items():
            status_name = {
                'completed': 'âœ… å·²å®Œæˆ',
                'downloading': 'â¬ ä¸‹è½½ä¸­',
                'pending': 'â³ å¾…ä¸‹è½½',
                'missing': 'â“ ç¼ºå¤±æ–‡ä»¶'
            }.get(status, status)
            print(f"  {status_name}: {count} ä¸ªæ–‡ä»¶")
        
        print()
        print(f"ğŸ’¡ çŠ¶æ€è¯´æ˜:")
        print(f"  ğŸ“¥ aria2c_urls.txt ä¸­çš„æ–‡ä»¶ = ç­‰å¾…ä¸‹è½½çš„æ–‡ä»¶")
        print(f"  ğŸ“ siblings ä¸­ä½†ä¸åœ¨ aria2c_urls.txt ä¸­ = å·²ä¸‹è½½å®Œæˆçš„æ–‡ä»¶")
        print(f"  â¬ ä¸‹è½½ä¸­ = å­˜åœ¨ .aria2 ä¸´æ—¶æ–‡ä»¶")
        print(f"  â“ ç¼ºå¤±æ–‡ä»¶ = åº”è¯¥å·²å®Œæˆä½†æ–‡ä»¶ä¸å­˜åœ¨")
        
        print()
        print(f"ğŸ“‹ ä¸‹è½½é…ç½®ç»Ÿè®¡:")
        print(f"  ğŸ”§ æœ‰ä¸‹è½½é…ç½®çš„æ–‡ä»¶: {download_config_count['with_config']} ä¸ª")
        print(f"  ğŸ“„ æ— ä¸‹è½½é…ç½®çš„æ–‡ä»¶: {download_config_count['without_config']} ä¸ª")
        
        # æ˜¾ç¤ºæ— ä¸‹è½½é…ç½®çš„æ–‡ä»¶ç¤ºä¾‹
        no_config_files = [f for f in file_list if not f.get('has_download_config', False)]
        if no_config_files:
            print(f"\nğŸ“‹ æ— ä¸‹è½½é…ç½®çš„æ–‡ä»¶ç¤ºä¾‹:")
            for i, file_entry in enumerate(no_config_files[:5]):
                status_icon = {
                    'completed': 'âœ…',
                    'downloading': 'â¬', 
                    'pending': 'â³'
                }.get(file_entry['status'], 'â“')
                print(f"  {status_icon} {file_entry['filename']}")
                
            if len(no_config_files) > 5:
                print(f"  ... è¿˜æœ‰ {len(no_config_files) - 5} ä¸ªæ–‡ä»¶")
        
        # æ˜¾ç¤ºæœ‰ä¸‹è½½é…ç½®çš„æ–‡ä»¶ç¤ºä¾‹
        config_files = [f for f in file_list if f.get('has_download_config', False)]
        if config_files:
            print(f"\nğŸ“‹ æœ‰ä¸‹è½½é…ç½®çš„æ–‡ä»¶ç¤ºä¾‹:")
            for i, file_entry in enumerate(config_files[:5]):
                status_icon = {
                    'completed': 'âœ…',
                    'downloading': 'â¬', 
                    'pending': 'â³'
                }.get(file_entry['status'], 'â“')
                print(f"  {status_icon} {file_entry['filename']}")
                
            if len(config_files) > 5:
                print(f"  ... è¿˜æœ‰ {len(config_files) - 5} ä¸ªæ–‡ä»¶")


def main():
    parser = argparse.ArgumentParser(description='HFD å…ƒæ•°æ®å¯¼å…¥å·¥å…·')
    parser.add_argument('hfd_dir', help='HFD å…ƒæ•°æ®ç›®å½•è·¯å¾„ (åŒ…å« .hfd ç›®å½•)')
    parser.add_argument('output_dir', help='æ•°æ®é›†è¾“å‡ºç›®å½•')
    parser.add_argument('--base-url', default='https://hf-mirror.com', help='åŸºç¡€URL (é»˜è®¤: https://hf-mirror.com)')
    parser.add_argument('--dry-run', action='store_true', help='åªæ˜¾ç¤ºæ‘˜è¦ï¼Œä¸å®é™…å¯¼å…¥')
    parser.add_argument('--db-path', default='downloads.db', help='æ•°æ®åº“æ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    try:
        # æŸ¥æ‰¾ .hfd ç›®å½•
        hfd_dir = Path(args.hfd_dir)
        if hfd_dir.name == '.hfd':
            hfd_metadata_dir = hfd_dir
        else:
            hfd_metadata_dir = hfd_dir / '.hfd'
            
        if not hfd_metadata_dir.exists():
            print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ° .hfd ç›®å½•: {hfd_metadata_dir}")
            sys.exit(1)
            
        # åˆ›å»ºå¯¼å…¥å™¨
        importer = HFDImporter(
            hfd_dir=str(hfd_metadata_dir),
            output_dir=args.output_dir,
            base_url=args.base_url
        )
        
        # æ˜¾ç¤ºæ‘˜è¦
        importer.print_summary()
        
        if args.dry_run:
            print("\nğŸ” è¿™æ˜¯è¯•è¿è¡Œæ¨¡å¼ï¼Œæœªå®é™…å¯¼å…¥æ•°æ®")
            return
            
        # ç¡®è®¤å¯¼å…¥
        print(f"\nâ“ æ˜¯å¦è¦å°†è¿™ä¸ª HFD ä»»åŠ¡å¯¼å…¥åˆ°æ•°æ®åº“ï¼Ÿ (y/N): ", end='')
        response = input().strip().lower()
        
        if response in ['y', 'yes']:
            # æ‰§è¡Œå¯¼å…¥
            task_manager = TaskManager(args.db_path)
            task_id = importer.import_to_system(task_manager)
            
            print(f"\nâœ… å¯¼å…¥æˆåŠŸï¼")
            print(f"ğŸ“‹ ä»»åŠ¡ID: {task_id}")
            print(f"ğŸ’¾ æ•°æ®åº“: {args.db_path}")
            print(f"\nğŸš€ ä½ ç°åœ¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ç»§ç»­ä¸‹è½½:")
            print(f"   python main.py --resume --task-id {task_id}")
            
        else:
            print("\nâŒ å¯¼å…¥å·²å–æ¶ˆ")
            
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main() 